\chapter{معرفی}

\section{مقدمه}
\hspace{30pt}
همه روزه، از ابزارهایی استفاده می‌کنیم و بدون توجه به شگفتی و تاثیر آن‌ها در زندگی روزمره، به راحتی آن‌ها را  نادیده می‌گیریم. یکی از این ابزارهای روزمره و البته پر قدرت، زبان است که هر روز به وسیله آن با اطرافیان ارتباط برقرار می‌کنیم، تفکر می‌کنیم و احساساتمان را بیان می‌کنیم. زبان طبیعی از ماقبل تاریخ همراه ما بوده و هم پای ما، دست خوش تغییرات بسیاری شده‌است. این ابزار، به قدری کارآمد و منعطف است که به حافظ امکان سرودن شعر می‌دهد، به حقوق‌دان‌ها امکان نوشتن قوانین اجتماعی را می‌دهد و به طنازان امکان لطیفه‌گویی می‌بخشد.  این میزان از جهان شمولی در نوع خود شگفت انگیز است.

 نمود زبان به شکل‌های متن و صوت را می‌توانیم به عنوان داده در علوم کامپیوتر\LTRfootnote{Computer Science} در نظر بگیریم. حال با توجه به این موضوع، اهداف متعددی از جمله نوشتن متن، درک معانی، ترجمه،تصحیح متون و... به وجود می‌آید. برای دستیابی به همه‌ی این اهداف به وسیله‌ی ماشین، زیر‌رشته‌ای در علوم کامپیوتر تعریف می‌شود که پردازش زبان طبیعی نام دارد که به اختصار \lr{NLP}\LTRfootnote{Natural Language Processing} گفته می‌شود. بررسی و تحلیل زبان‌های طبیعی مثل فارسی، انگلیسی، اردو و... از وظایف پردازش زبان طبیعی است.

خوانایی هر متنی مهم‌ترین دلیل تحریر آن است. با این وجود، ممکن است اشتباهاتی از سوی نویسنده باعث کاهش خوانایی متن شود. این اشتباهات، در دو دسته‌ی معنایی و نحوی تقسیم می‌شود. اشتباه‌های معنایی شامل بیان جمله به شکل نادرست و انتخاب کلمه‌های غلط که باعث کاهش درک مطلب و کج فهمی مخاطب می‌شوند. اشتباه‌های نحوی که شامل غلط املایی، عدم استفاده و یا استفاده ناصحیح از علائم اشاره مانند نقطه، ویرگول، پرانتز و غیره، پاراگراف بندی ناصحیح و همچنین فاصله‌گذاری کلمات و بین کلمات و یا فاصله‌های مربوط به علائم اشاره می‌شود.

فاصله‌گذاری متون یکی از مهمترین عناصر نحوی آن است. به وسیله‌ی فاصله، حدود هر کلمه مشخص می‌شود، علائم نگارشی معنا پیدا می‌کنند و نظم، آراستگی و انسجام متن حفظ می‌شود و خواننده متوجه می‌شود که پس از هر فاصله، با واحد معنایی مستقلی روبرو شده است. اشتباهات رایج در این زمینه شامل عدم استفاده از فاصله و نیم‌فاصله در جای درست و استفاده‌ی نابجا از این دو در محل نادرست است. این اشتباهات به شکل قابل توجه‌ای خوانایی متن را تحت تاثیر قرار می‌دهند، سرعت خوانش را کاهش می‌دهند و در برخی موارد ممکن است معنی تازه و دور از نظر نویسنده به متن بدهند. از دلایل اهمیت این موضوع می‌توان به چسبیدن برخی حروف به یکدیگر نام برد که می‌توانند ظاهر کلمه را کاملاً دگرگون کنند. همچنین عبارات متعددی در زبان فارسی وجود دارند که در صورت قراردادن فاصله بین آن‌ها معنایی متفاوت از صورت چسبیده‌ی خود می‌گيرند؛ برای مثال «اخطار داده» و «عهد نامه». حتی در بسیاری از کلمات مشتق، علاوه بر تغییر معنا، می‌تواند نقش کلمه را در جمله دستخوش تغییرات کند مثل «گوشت‌ِ تلخ» و «گوشت‌تلخ» و «دوستان دانشگاهی من» و «دوستان دانشگاه یمن». هر چند بسیاری از این اشتباهات توسط ذهن خواننده به وسیله درک محتوای محیطی\LTRfootnote{Peripheral context}، تصحیح می‌شوند و خواننده می‌تواند مطلب را درک کند. با این حال این اشتباهات می‌توانند مشکلاتی را در خوانش به وجود بیاورند.

در اینجا نیاز است که با دو کاراکتر فاصله و نیم‌فاصله بیشتر آشنا شویم. فاصله که بر روی اکثر صفحه‌کلید‌ها بزرگ‌ترین کلید را به خود اختصاص داده است، یکی از مهم‌ترین کاراکتر‌های نگارشی است. این کاراکتر برای تفکیک واحد‌های معنادار و همچنین برای تفکیک جملات استفاده می‌شود. از دیگر موارد استفاده‌ی فاصله می‌توان از همنشینی آن‌ها در کنار علائم اشاره نام برد. کد یونی‌کد
\LTRfootnote{Unicode} آن \lr{U+0020}
است و یکی از پر کاربرد ترین کاراکتر‌های هر متنی به شمار می‌آید. \cite{unicode2020space}


پیش از رسیدن به نیم‌فاصله، لازم است، درباره اهمیت وجودی چنین کاراکتری، بحث کنیم. در ابتدا، باید در نظر گرفت که در رسم خط فارسی حروف به دو دسته تقسیم می‌شوند. دسته‌ی اول، که شامل بیشتر حروف الفبای فارسی می‌شود، به حرف قبل و بعد از خود می‌چسبند، مانند حرف «ب». دسته‌ی دوم فقط به حرف قبل از خود می‌چسبند. همانند حروف «الف» و «دال». این در صورتی است که هر یک با چسبیدن به حروف قبلی یا بعدی، می‌توانند شکل خود را تغییر ‌دهند که در نهایت شکل ظاهری کلمه را به کلی دگرگون کند. با این وجود در بسیاری از موارد نیاز است که دو حرف یه یکدیگر نچسبند.

برای سهولت در نوشتار و جدا کردن حروف از یکدیگر، کاراکتری به نام نیم‌فاصله در صفحه‌کلید‌های فارسی تعریف شده است که کاراکتر جدا کننده حروف از یکدیگر محسوب می‌شود. نام انگلیسی این کاراکتر \lr{Zero Width NonJoiner (ZWNJ)} می‌باشد و کد یونی‌کد آن
\lr{U+200C} است.
نیم‌فاصله یک کاراکتر غیرچاپی است که در املای چند زبان، از جمله فارسی استفاده می‌شود. در زبان فارسی، نیم‌فاصله بین تکواژهای آزاد در کلمات مرکب (یا شکل‌های ترکیبی) و همچنین بین یک یا چند تکواژ آزاد و یک یا چند تکواژ وابسته برای جلوگیری از پیوستن حروف استفاده می‌شود.
اگرچه مجموعه قوانینی در مورد استفاده از فاصله و نیم‌فاصله توسط نهاد نظارتی زبان فارسی وضع شده است، اما تنها عده کمی در نوشتن فارسی رسمی از آن‌ها پیروی می‌کنند، چه رسد به زبان غیر رسمی. \cite{unicode2005-ZWNJoriginal}
\cite{unicode2003-ZWNJrecommendation}
\cite{unicode2012-ZWNJ-marks}

از کاربرد‌های عملی نیم‌فاصله می‌توان به جدا کردن «می» از مابقی فعل«می‌آیم»، بین «بی» و کلمات پس از آن «بی‌حوصله» بین صفت و موصوف مقلوبی «نرم‌افزار»، قید‌های چند‌جزئی «روی‌هم‌رفته» و… اشاره کرد. نیم‌فاصله به دلایل مختلفی نظیر در دسترس نبودن کاراکتر در صفحه‌کلید‌ها، بی‌دقتی و عدم اطلاع بسیاری از افراد از وجود چنین کاراکتری،یا اشتباه‌های نگارشی اشاره کرد. در متون فارسی به ویژه متون شبکه‌های اجتماعی و متن‌هایی که به وسیله‌ی گوشی‌های موبایل نوشته شده‌اند، نیم‌فاصله استفاده نشده و یا کمتر استفاده می‌شود. یکی از دلایل قرارندادن نیم‌فاصله نچسبیدن حروف به حرف بعدی است که با توجه به  تشابه شکل ظاهری هر‌دو نوشتار، نیم‌فاصله استفاده نمی‌شود برای مثال «روند‌ها». با این حال اهمیت نیم‌فاصله در نوشتار صحیح انکارناپذیر است.

قوانین نگارش فاصله و نیم‌فاصله در بسیاری از وب سایت‌ها و منابع آموزش نگارش بیان شده‌است با این وجود، اگر بخواهیم منبع واحدی برای این مهم معرفی کنیم، فرهنگستان  زبان و ادب فارسی \cite{PersianOrthography2015}مهم‌ترین منبع ما برای معیار منتخب  بوده است. با توجه به این موضوع که سنجش مدل‌ها توسط رایانه و از روی بدنه‌های تصحیح شده انجام می‌گیرند. در سنجش خود بدنه‌ها، از قوانین فرهنگستان استفاده شده‌است که در فصل نتایج به آن‌ها خواهیم پرداخت.

حال سوالی که به وجود می‌آید این است که تصحیح فاصله و نیم‌فاصله در متون به چه شکلی انجام می‌گیرد؟ در پاسخ به این سوال باید گفت که در مواردی همچون کتاب و نشریات، که متن باید کیفیت نگارشی بالایی داشته باشد، به طور معمول، کار تصحیح به عهده ویراستار\LTRfootnote{Editor}است. ولی برای متن‌هایی که ویراستاری تخصصی نمی‌شوند، در برنامه‌های پردازش متن همانند \lr{Microsoft Word} از زبان، یک دایره لغات یا دیکشنری\LTRfootnote{Dictionary} نگاه داشته می‌شود که عبارات متن نوشته شده، با آن دایره لغات بررسی می‌گردد. اگر عبارات وارد شده در دیکشنری نباشد، به نوعی به کاربر اخطار داده می‌شود که احتمالاً عبارت شما نادرست است. در این روش‌ها تصحیح به وسیله‌ی نیروی انسانی انجام می‌گیرد، زیرا اگر جای‌گذاری عبارات دیکشنری انجام پذیرد، می‌تواند به محتوای متن آسیب بزند و یا آن را تحریف کند. همچنین، این روش فقط تصحیح فاصله و نیم‌فاصله انجام نمی‌دهد. پس اگر سیستم قصد دارد که تصحیح فاصله و نیم‌فاصله انجام دهد، بهتر است کار را به تنهایی انجام دهد. به این صورت که متن را دریافت کرده و نسخه‌ی تصحیح شده فاصله و نیم‌فاصله را جای‌گذاری کند.

به طور کلی برای طراحی چنین سیستم‌هایی، سه روش وجود دارد. در روش اول، با استفاده از دایره لغات بزرگ می‌توان کار تصحیح‌ را انجام داد\LTRfootnote{Dictionary-based Methods}. به این شکل که اگر عبارات عیناً منطبق بر عبارات داخل دیکشنری باشند، فاصله‌گذاری‌ها مطابق با دیکشنری تصحیح می‌شود. ایراد این روش، گردآوری مشکل دایره لغات، و همچنین محدود کردن دامنه کار سیستم به دیکشنری می‌باشد.

در روش دوم با استفاده از سیستم‌های قانون محور\LTRfootnote{Rule-based Methods} می‌توان کار تصحیح‌ را انجام داد چرا که قوانین فاصله محدودند و می‌توان  آن‌ها را تا حدی پیاده‌سازی کرد. از ایرادهای این روش، می‌توان به در نظر نگرفتن استثناها و نیاز به اطلاعات فراوان از متن و ساختار آن برای تصحیح اشاره کرد.

روش سوم استفاده از مدل‌های یادگیری ماشین و یادگیری عمیق است\LTRfootnote{Learning Methods}. در این روش می‌توان به اشکال مختلفی با مسئله برخورد کرد که هرکدام مزایا و معایب مختص خود را دارند. روشی که ما برای مواجه با این مسئله انتخاب کرده‌ایم، روش استفاده از مد‌ل‌های زبانی از پیش آموزش دیده در فرایند تصحیح است به طوری که با استفاده از اطلاعات حفظ شده در مدل زبانی کار‌ تصحیح‌ را انجام دهیم.

\section{معرفی مسئله}
\hspace{30pt}
مسئله‌ای که ما برای این پژوهش تعریف می‌کنیم، مسئله تصحیح فاصله و نیم‌فاصله در متن فارسی است. به این صورت که مدل، متن از پیش‌نوشته شده‌ای را دریافت کند و عمل تصحیح فاصله‌ها و نیم‌فاصله‌های متن را انجام دهد. سپس متن تصحیح شده را بازگردانی کند. در نتیجه مدل می‌تواند بدون ایجاد تغییرات اساسی به متن، عمل تصحیح را روی متن انجام دهد. هدف ما رسیدن به محصولی است که بتواند این کار را در سطح کلان، با دقت و صحت قابل قبولی انجام‌دهد.

\section{چالش‌های پیش‌رو}
\hspace{30pt}
چالش‌های متعددی پیش‌روی این تحقیق قرار گرفته‌اند. ازجمله‌ی این چالش‌ها می‌توان به جمع‌آوری داد‌ه‌های آموزشی اشاره کرد. این داده‌ها باید شامل نگارش صحیح و به‌روز باشند تا مدل بتواند از روی این داده‌ها آموزش ببیند و نحوه صحیح فاصله‌گذاری را از آن‌ها یاد بگیرد. ساختار داده از اهمیت بالایی برخوردار است، چرا که این پژوهش در سطح کاراکتر انجام می‌پذیرد ولی اکثر مدل‌های زبانی بزرگ در سطح کلمه و یا زیر‌کلمه کار می‌کنند پس ساختار داده‌ی ما به نحوی است که علاوه بر سطح کلمه، اطلاعات سطح کاراکتر را نیز در بر بگیرد که پیدا کردن این ساختار را چالش برانگیزتر می‌کند. پردازش بهینه برای مدل‌های زبانی بزرگ حائز اهمیت است، زیرا با کوتاه کردن مدت آموزش می‌توان تعداد ایپاک‌ها\LTRfootnote{epochs}را افزایش داد و تعداد آزمایش بیشتری در را زمان مشخص انجام داد. همچنین پیدا کردن ساختار مدل و مدل زبانی از پیش آموزش دیده چالشی برای این پژوهش بود.

\section{کلیات روش پیش‌رو}
\hspace{30pt}
 روشی که ما برای انجام این پژوهش انتخاب کردیم، شامل، انتخاب داده‌های مناسب و آماده‌سازی آن‌ها برای آموزش مدل‌های شبکه عصبی مصنوعی، مشخصاً از نوع شبکه‌های ترانسفورمر رمزگذار\LTRfootnote{encoder only transformer models}می‌باشد. این دسته از شبکه‌های عصبی به دلیل خاصیت دوسویه بودن، امکان رسیدن به هدف ما را فراهم می‌کنند. پس از آماده سازی داده‌ها برای آموزش، تصدیق و سنجش مدل‌های منتخب مدل‌ها آماده بهره‌برداری می‌شوند. برای بهره‌برداری، فرآیند دریافت متن خام و اصلاح آن توسط مدل‌ها صورت می‌گیرد. در نهایت سکویی برای استفاده‌ی عموم از محصول این پژوهش، طراحی و ساخته می‌شود که عموم فارسی زبانان بتوانند از محصولات این پژوهش استفاده کنند.

\section{معرفی فصول}
\hspace{30pt}
این پایان‌نامه به چند بخش تقسیم می‌شود. فصل اول شامل کلیاتی حول‌ محور پژوهش است و در مورد اهمیت و هدف آن بحث می‌کند. فصل دوم در مورد زمینه‌ی تحقیق است و به مطالبی می‌پردازد که خواننده برای فهم پژوهش باید از آن‌ها مطلع باشد، در فصل سوم به کارهای مرتبط و پیشین می‌پردازیم و با کارهایی این چنین آشنا می‌شویم، در فصل چهارم، که شامل هسته‌ی اصلی تحقیق ماست، به نحوه جمع آوری دیتا و پردازش آن را به صورت تفصیلی می‌پردازیم. همچنین با بررسی مدل‌ها، نحوه‌ی کارکرد آن را مورد بررسی قرار می‌دهیم و با جزئيات مدل‌ها و تفاوت‌های آن‌ها آشنا می‌شویم و کارهای صورت گرفته را مورد مطالعه قرار‌می‌دهیم. در فصل پنجم نتایج تحقیق را بررسی می‌کنیم و با هر کدام آشنا می‌شویم. در فصل پایانی، نتیجه‌گیری و جمع‌بندی تحقیق و کارهایی که می‌توان با این نوع مدل انجام داد مورد مطالعه قرار می‌دهیم.

\chapter{مفاهیم پایه}
\hspace{30pt}
هدف از این فصل آشنا کردن خواننده با مفاهیم پایه‌ی این پژوهش است. در هر یک از بخش‌ها و زیر بخش‌های این فصل، به مطالب و مفاهیم پایه‌ای که خواننده این پایان‌نامه باید از آن‌ها اطلاع داشته باشد خواهیم پرداخت.

در بخش اول به داده‌های متنی می‌پردازیم. در این بخش به نحوه ی پردازش داده‌‌های متنی به صورت کلی و به طور مشخص به روشی که ما برای پردازش این داده‌ها استفاده می‌کنیم می‌پردازیم. در بخش دوم به برچسب‌زنی توالی می‌پردازیم و با نحوه‌ی کارکرد این نوع برچسب‌زنی و موارد استفاده‌ی آن آشنا می‌شویم. در بخش سوم با یادگیری انتقالی آشنا می‌شویم و در بخش چهارم به مکانیسم توجه و محصول آن که مدل‌های ترانسفورمر است می‌پردازیم و با روش کارکرد آن‌ها در حدی که بتوانیم این اطلاعات را در فهم این پژوهش به کار بیریم آشنا مى‌شویم. در بخش پنجم مدل زبانی برت که هسته‌ی اصلی مدل این پژوهش است را بررسی می‌کنیم و همچنین به معرفی ویژگی‌های آن می‌پردازیم. با بخش‌ها و اجزای تشکیل دهنده‌ی آن آشنا می‌شویم. همچنین به مشتقات مورد استفاده‌ی این مدل زبانی می‌پردازیم که در این پژوهش مورد استفاده قرار گرفته‌اند.

\section{داده‌های متنی}
\hspace{30pt}
داده‌های متنی، اگر فراوان‌ترین نوع داده‌ی موجود نباشند، یکی از فراوان‌ترین نوع داده‌های موجود در دنیای امروزی هستند. با در نظر گرفتن تنوع زبانی موجود در جهان و مجموع انواع و اقسام این نوع‌ داده می‌توان تصور کرد که چه حجم عظیمی از آن موجود است. در یک داده‌ی متنی ساده مانند یک جمله اطلاعات بسیاری وجود دارد. بطور مثال معنای جمله، اجزای کلام\LTRfootnote{part of speech (POS)} یا همان نقش هر یک از کلمات در جمله، قوانین نگارش و….

از میان همه‌ی این خواص، باید به خاصیت سری زمانی بودن آن نیز توجه کرد. به عبارت دیگر تقدم و تأخر کلمات در جمله اهمیت دارند و تغییر در آن‌ها می‌تواند اطلاعات موجود در متن را دست خوش تغییرات کند. خاصیت سری زمانی لزوماً همه‌ی ابعاد اطلاعات متن را شامل نمی‌شود. برای مثال، بسیاری از جابجایی‌ها در جمله، معنای جمله را تغییر نمی‌دهند. در این پژوهش، خاصیت سری زمانی برای ما اهمیت بسیاری دارد و نوع مدل ما را تحت تاثیر خود قرار می‌دهد. در ادامه می‌خواهیم با انواعی از پردازش داده‌های متنی بپردازیم.

هر کاراکتر، حرف، عدد و علائم نگارشی که تایپ می‌شود، به شکل یک کد با استاندارد رمزگذاری مشخص ذخیره می‌شود. برای مثال یکی از محبوب ترین رمز‌گذاری‌ها در اینترنت رمز‌گذاری \lr{UTF-8} است. در رمزگذاری‌ها، هر کاراکتر، صرف نظر اینکه حرف ،عدد و... باشد، به یک کد که متناظر آن کاراکتر است، نگاشت می‌شود. سپس این کدها کنار یکدیگر نوشته شده و ذخیره می‌شوند‌. برای نمایش، این کد‌ها خوانده می‌شوند‌ و کاراکتر متناظر هر کد، به ترتیب نمایش داده می‌شود. این فرآیند کلی ذخیره و نمایش هر متنی در رایانه‌ها است.

کدهای مشخص شده در رمزگذار‌های مختلف به ترتیب حروف الفبا و یا ترتیب‌های دیگر که مد نظر سازنده‌ی رمزگذار هستند، طراحی شده‌اند و اختلاف کد‌ها از یکدیگر کاملا بی‌معنا است و صرفاً با هدف یکتا بودن کد‌ها به این شکل قرار‌داد شده‌اند. در مدل‌های هوش مصنوعی فواصل کد‌ها از یکدیگر اهمیت دارد پس برای این موضوع متن‌ باید به یک فضایی نگاشت شود که بتوانیم فواصل را به درستی تعریف کنیم. اکثر این رمزگذاری‌ها، مدت‌ها از زمان ساخت آن‌ها می‌گذرد و تغییر در این رمزگذاری‌ها به دلیل تثبیت آن‌ها، قابل انجام نیست.

به فرآیند تقسیم متن به قسمت‌های کوچکتر، با توجه به معنای آن‌ها توکنیزه‌کردن یا توکنیزه‌سازی\LTRfootnote{tokenization} متن مى‌گویند. این فرآیند هرچند به معنای تقسیم متن به اجزای با معنا گفته می‌شود که نام آن‌ها توکن\LTRfootnote{token} است؛ اما در ادبیات پردازش زبان طبیعی کلمات توکنیزه کردن و توکن، گاهاً به معنای تقسیم متن به اجزا به صورت کلی نیز دلالت دارد. به صورت کلی متن می‌تواند به چند شکل توکنیزه شود.

 روش اول، توکنیزه‌سازی کلمات است. به این شکل که هر یک از کلمات معنادار به عنوان یک توکن مجزا تقسیم می‌شوند‌ این کلمات معمولا به وسیله فاصله از هم جدا می‌شوند. شکل \ref{fig:tokenizers} مثال این نوع توکنیزه‌سازی است. روش دوم شامل توکنیزه‌سازی زیر‌کلمات است. در این روش یک واحد معنایی می‌تواند به یک یا چند توکن تقسیم شود. روش‌های متعددی همچون \lr{Byte-Pair-Encoding}\cite{sennrich2016byte} وجود دارد که بتواند زیر‌کلمه‌های درستی را انتخاب و جداسازی کند. این روش پراستفاده ترین روش توکنیزه‌سازی در مدل‌های زبانی بزرگ است. در ادامه دلایل انتخاب این روش در مدل‌های زبانی بزرگ را مورد بررسی قرار می‌دهیم. شکل \ref{fig:tokenizers} مثال این نوع توکنیزه‌سازی است. روش سوم، روش توکنیزه‌سازی در سطح کاراکتر است. در این روش هر یک از کاراکترها به شکل یک توکن تقسیم می‌شوند. از این روش توکنیزه‌سازی در این پژوهش استفاده شده است شکل \ref{fig:tokenizers} مثال این نوع توکنیزه‌سازی است.
 \begin{figure}[H]
      \centering
      \includegraphics[width=1\linewidth]{Figures/f01-tokenizers.jpg}
      \caption{مثالی از انواع توکنیزه‌سازی}
      \label{fig:tokenizers}
  \end{figure}

هر یک از روش‌های توکنیزه‌سازی مزایا و معایب خود را دارند. توکنیزه‌سازی کلمات، کمترین تعداد توکن از یک متن را به ما می‌دهد، ولی دایره‌ی لغات بزرگتری دارد. زیرا برای هر یک از کلمات مرکب یک سطر در دایره‌ی لغات خود ایجاد می‌کند. در این روش اطلاعات داخل کلمه‌های مرکب دریافت نمی‌شود. برای مثال کلمه دانشگاه با دانشکده ارتباطی با هم ندارند. در روش دوم، زیر‌کلمه هر یک از اجزای پرتکرار داخل کلمات به عنوان توکن مجزا طبقه بندی می‌شوند در این روش اندازه دایره لغات کوچکتر از روش قبل می‌باشد. همچنین اطلاعات اجزای کلمات مرکب را ذخیره می‌کند ولی تعداد توکن‌ها به ازای متن یکسان از روش اول بیشتر خواهد بود. در مثال ما هر یک از دو کلمه دانشگاه و دانشکده از دو توکن دانش و گاه یا کده تشکیل می‌شوند که قرابت بیشتری با معنا و مفهوم کلمات دارد. روش سوم توکنیزه‌سازی داده‌ها شامل توکنیزه‌سازی هر یک از کاراکتر‌های متن است. این روش، کوچکترین دایره لغات را دارد، اما در عوض بیشترین تعداد توکن به ازای متن را تولید می‌کند. دریافت اطلاعات کلمه یا زیر کلمه در این روش، کاملا بستگی به مدل یادگیری ماشین یا مدل یادگیری عمیق دارد.

از آنجایی که این پژوهش در مورد فاصله و نیم‌فاصله است توکنیزه‌سازی در سطح کاراکتر برای ما اهمیت دارد. پس به توضیح بیشتر در مورد این نوع توکنیزه‌سازی می‌پردازیم. کل فرایند را در دو بخش می‌توان شرح داد.
 در بخش اول متن به توکنیزه‌ساز\LTRfootnote{tokenizer} داده می‌شود و در همان ابتدا به قسمت‌های کوچکتر که در نوع سوم، شامل کاراکتر‌های متشکل آن است، افراض می‌شود و توکن‌های ویژه‌ای نظیر توکن مشخص کننده ابتدا و انتهای جمله به آن افزوده می‌شود. سپس در مرحله ی دوم هر یک از توکن‌ها به یک نشانه\LTRfootnote{identifier(id)} تبدیل می‌شوند. این نشانه‌ها فضای نگاشت هر یک از توکن‌ها به بردار متناظر خود هستند. هر یک از نشانه‌ها به برداری متناظر مرتبط مى‌شوند، که به عنوان یک کار مجزا توسط مدلی آموزش دیده‌اند تا فاصله‌ی بردار‌ها از یکدیگر معنا و مفهوم پیدا کند.
در نهایت متن ما پس از تقسیم، افزودن توکن‌های ویژه و تبدیل توکن‌ها به نشانه‌های بردارهای هر توکن، به لیستی از نشانه‌های عددی توکن‌ها می‌رسد که خروجی فرآیند است.




\section{برچسب زنی توالی}
\hspace{30pt}
برچسب‌زنی توالی عبارت است از مقرر کردن یک یا چند برچسب به هر یک از اجزای سری متوالی. بسیاری از تکلیف‌های پردازش زبان طبیعی مانند تشخیص اجزای کلام و تشخیص موجودیت‌های نامدار\LTRfootnote{Named Entity Recognition(NER)} و از این نوع برچسب‌گذاری استفاده می‌کنند.
به عنوان مثال فرض کنید یک سری از توکن‌ها داریم و یک آرایه متناظر برای برچسب‌ها نیز وجود دارد که هر درایه آن حاوی برچسب توکن متناظر آن در آرایه‌ى توکن‌ها است. شکل \ref{fig:seq_labeler} مثالی از این نوع به چسب‌زنی است.\cite{jurafsky2024speech}
\begin{figure}[H]
      \centering
      \includegraphics[width=1\linewidth]{Figures/f02-seq_labeler.jpg}
      \caption{مثالی از برچسب‌گذاری توالی (اجزای کلام)}
      \label{fig:seq_labeler}
  \end{figure}

\section{یادگیری انتقالی}
\hspace{30pt}
یادگیری انتقالی، شیوه‌ای قدرتمند در یادگیری ماشینی است که، به ما امکان استفاده از دانش به دست آمده توسط یک مدل آموزش دیده و به کار گیری آن  در یک کار مرتبط با کار قبلی به را می‌دهد. یادگیری انتقالی، آموزش مدل را تسریع می‌کند و عملکرد را بهبود می‌بخشد. تصور کنید که در هنگام انجام یک کار جدید، شروع خوبی داشته باشید. یادگیری انتقالی دقیقاً همین امکان را فراهم می‌کند. یادگیری انتقالی شبیه به گرفتن دانش از یک حوزه و به کار بردن آن در حوزه دیگر است. یک مدل آموزش داده شده در یک کار، پایه و اساس یک کار مرتبط می‌شود. به جای اینکه از صفر شروع کنیم، دانش موجود را تغییر می‌دهیم که منجر به همگرایی سریعتر و نتایج بهتر می‌شود.

تصور کنید یک مدل «الف» دارید که به طور خاص برای کار پاسخ به سوال آموزش دیده است.
اکنون، شما‌ می‌خواهید یک مدل را برای یک کار متفاوت آموزش دهید به عنوان مثال، تشخیص شباهت دو جمله؛ به جای آموزش مدل «ب» از ابتدا، آن را با همان وزن‌های مدل «الف» مقدار دهی اولیه می‌کنید. این انتقال دانش از «الف» به «ب» فرآیند آموزش را بسیار جلوتر از حالتی که وزن‌ها به صورت تصادفی مقدار دهی اولیه شده‌اند قرار می‌دهد. مدل «ب» با آموزش بر روی داده‌های وظیفه «ب» تنظیم دقیق‌\LTRfootnote{fine-tune} ‌می‌شود. مدل «الف» از پیش آموزش دیده «ب» به سمت وزن‌های بهینه هدایت می‌کند و در نهایت، تنظیم دقیق، مدل را با ویژگی‌های وظیفه «ب» تطبیق می‌دهد.

یادگیری انتقالی باعث صرفه جویی قابل ملاحضه‌ای در محاسبات، زمان و داده‌ها می‌شود. مدل‌های از پیش آموزش دیده، درک آماری زبان یا ویژگی‌هایی را به دست می‌آورند که با آموزش برای همان کار قابل دستیابی نبوده است.
در بینایی کامپیوتری\LTRfootnote{computer vision}، یادگیری انتقالی برای سال‌ها موفقیت‌آمیز بوده و اغلب از مدل‌های از پیش آموزش دیده، از آن استفاده می‌کنند. همچنین این مفهوم به شکل قابل توجه‌ای در مدل‌های امروزی پردازش زبان طبیعی استفاده می‌شود و نتایج خوبی را به همراه داشته است.\cite{pan2009survey}\cite{transfer-learning}\cite{raffel2019exploring}


\section{مدل‌های زبانی}
\hspace{30pt}
مدل‌های زبان بزرگ و یا به اختصار \lr{LLM}\LTRfootnote{Large Language Models} دسته‌ای از مدل‌های پایه هستند که بر روی مقادیر بسیار زیاد داده آموزش دیده‌اند و این مدل‌ها را قادر به درک و تولید زبان طبیعی و انواع دیگر محتوا برای انجام طیف وسیعی از وظایف می‌کنند. آن‌ها به لطف نقشی که در پیشبرد هوش مصنوعی مولد\LTRfootnote{Generative-AI} داشتند، به نامی شناخته شده تبدیل شده‌اند.

مدل‌های زبانی بزرگ، در واقع، الگوریتم‌های یادگیری عمیق هستند که می‌توانند با استفاده از مجموعه داده‌های بسیار بزرگ محتوا را شناسایی، خلاصه، ترجمه، پیش‌بینی و تولید کنند. آن‌ها این توانایی‌ها را با یادگیری روابط آماری از متن‌های بسیار بزرگ در طی یک فرآیند آموزشی فشرده محاسباتی خود که نظارت شده و نیمه نظارت شده می‌باشد به دست می‌آورند. مدل‌های زبانی بزرگ شبکه‌های عصبی مصنوعی هستند که بزرگترین و تواناترین آن‌ها با معماری مبتنی بر ترانسفورمر فقط رمزگشا ساخته شده‌اند. که در بخش بعدی به آن‌ها می‌پردازیم.

مدل‌های زبانی بزرگ کاربرد‌های مستقیم و غیر‌مستقیم بسیاری دارند. یکی از ساده‌ترین کاربردهای عملی برای مدل‌های زبانی بزرگ، ترجمه متن‌ها است. کاربر می‌تواند متن را وارد کند و از آن بخواهد به زبان دیگری ترجمه شود. در این صورت سیستم به طور خودکار ترجمه متن را آغاز می‌کند. یکی دیگر از موارد استفاده رایج برای مدل‌های زبان، ایجاد محتوا است. مدل‌های زبانی بزرگ کاربران را قادر می‌سازد تا طیف وسیعی از محتوای نوشتاری را از وبلاگ‌ها و مقالات گرفته تا داستان‌های کوتاه، خلاصه‌ها، پرسش‌نامه‌ها، نظرسنجی‌ها و پست‌های رسانه‌های اجتماعی را تولید کنند.
مدل‌های زبانی بزرگ، تجارت الکترونیک و صنعت خرده فروشی را با ارائه ابزارهای ترجمه بلادرنگ، امکان ترجمه کارآمد اسناد برای مشاغل جهانی و تسهیل بومی‌سازی نرم افزارها و وب سایت‌ها را متحول می‌کنند. \cite{brown2020language}

مدل‌های زبانی بزرگ نشان دهنده پیشرفت قابل توجه‌ای در پردازش زبان طبیعی و هوش مصنوعی هستند و از طریق رابط‌هایی مانند \lr{Chat GPT-3} و \lr{GPT-4} \cite{openai2023chatgpt} که پشتیبانی مایکروسافت را به دست آورده‌اند، به راحتی در دسترس عموم قرار دارند. نمونه‌های دیگر شامل مدل‌های \lr{Llama}\cite{touvron2023llama} متا و نمایش‌های رمزگذار دوطرفه\LTRfootnote{‌bidirectional-encoder} گوگل از ترانسفورمرها \lr{(BERT و RoBERTa)}\cite{devlin2018bert}\cite{liu2019roberta} و مدل‌های \lr{PalM1}\cite{palm1} هستند. همانطور که آن‌ها به تکامل و بهبود ادامه‌ می‌دهند، مدل‌های زبانی بزرگ آماده هستند تا نحوه تعامل ما با فناوری و دسترسی به اطلاعات را تغییر دهند و آن‌ها را به بخشی اساسی از چشم انداز دیجیتال مدرن تبدیل کنند.

\section{مکانیسم توجه و مدل‌های ترانسفورمر}
\hspace{30pt}
یکی از مهم‌ترین دلایل پیشرفت شگفت انگیز مدل‌های زبانی امروزی، مکانیسم توجه است.  مکانیسم توجه، در سال 2017 با مقاله پیشگامانه با عنوان «توجه تنها چیزی است که نیاز دارید» معرفی شد. این مقاله توسط \lr{Ashish Vaswani} و همکاران \lr{Google Brain} و دانشگاه تورنتو،  رویکرد جدیدی را برای مدل‌سازی توالی معرفی کرد.\cite{vaswani2017attention}
آن‌ها بسیاری از زمینه‌های یادگیری ماشین را متحول کرده‌اند و همچنان یک عنصر اساسی در بسیاری از سیستم‌های هوش مصنوعی مدرن هستند.

 این مکانیسم به مدل‌ها اجازه می‌دهد که به جای فقط چند کلمه، درکی از کل متن داشته باشند. مکانیسم توجه مدل‌ها را قادر می‌سازد تا به صورت پویا تمرکز خود را تخصیص دهند و با زمینه‌های مختلف سازگار شوند. ساختار‌های داده‌های پیچیده را به طور مؤثر مدیریت کنند. به طور کلی، مکانیسم توجه روشی است که عملکرد مدل را با تمرکز بر روی اطلاعات مرتبط افزایش می‌دهد. این روش، مدل‌ها را قادر می‌سازد تا به طور انتخابی بر بخش‌های مختلف داده‌های ورودی تأکید کند و سطوح مختلف اهمیت یا وزن را به عناصر خاص اختصاص دهند.
مکانیسم توجه، وزن توجه‌ای برای عناصر یا ویژگی‌های مختلف داده‌های ورودی ایجاد می‌کند. این وزن‌ها میزان اهمیتی که هر عنصر در خروجی مدل نقش دارد را تعیین می‌کنند. وزن توجه، بر اساس ارتباط یا شباهت بین عناصر و بردار‌های زمینه\LTRfootnote{context vectors} محاسبه می‌شود.

در تکامل شگفت انگیز هوش مصنوعی، ترانسفورمرها به عنوان یک تحول بزرگ ظاهر شده‌اند. این معماری شبکه‌های عصبی قدرتمند، پردازش زبان طبیعی، بینایی کامپیوتر و سایر وظایف یادگیری ماشین را متحول کرده است. معماری ترانسفورمر در پیشگامانه «توجه تنها چیزی است که نیاز دارید» معرفی شد.
در قلب ترانسفورمرها مکانیسم توجه به خود نهفته است. برخلاف شبکه‌های عصبی بازگشتی که توالی‌ها را به صورت متوالی پردازش می‌کنند، ترانسفورمر‌ها توالی‌های ورودی را به صورت موازی پردازش می‌کنند.

توجه به خود که گونه‌ای از مکانیسم توجه برای آموزش مدل‌های خود نظارت‌گر است، به مدل، این امکان را می‌دهد که اهمیت کلمات مختلف را در یک دنباله بر اساس ارتباط آن‌ها با زمینه فعلی ارزیابی کند. این موازی‌سازی، آموزش و استنتاج کارآمد را امکان پذیر می‌کند و ترانسفورمرها را بسیار مقیاس پذیر می‌کند.
ترانسفورمرها معمولاً از دو جزء اصلی رمزگذار و رمز‌گشا تشکیل می‌شوند. رمزگذار، داده‌های ورودی را پردازش می‌کند و رمزگشا خروجی نهایی را تولید می‌کند. به عنوان مثال، زبان مبدأ در ترجمه توسط رمزگذار پردازش می‌شود و ترجمه زبان مقصد به وسیله رمزگشا تولید می‌شود. این معماری در کارهایی مانند ترجمه ماشینی و خلاصه سازی برتری دارد.

ترانسفورمرها فقط به ترتیب کلمات متکی نیستند. در عوض، آن‌ها از رمزگذاری موقعیتی\LTRfootnote{positional encoding} برای درک موقعیت هر کلمه در یک دنباله استفاده می‌کنند. رمزگذاری‌های موقعیتی به حفظ محتوا، حتی برای عناصر دور کمک می‌کنند و به ترانسفورمرها اجازه می‌دهند تا دنباله‌های طولانی را به طور مؤثری اداره کنند.

ترانسفورمرها متن ورودی را به صورت چندگرام\LTRfootnote{N-gram} که از توکن‌‌های معمولاً زیر کلمه‌ای تشکیل شده‌اند، دریافت می‌کنند و از طریق نگاشت کلمه به بردار تبدیل می‌کنند. هر توکن نشان دهنده یک جفت کلید-مقدار\LTRfootnote{key-value} است. در هر لایه، هر توکن با استفاده از مکانیزم توجه چند سر موازی\LTRfootnote{multi-head attention} در پنجره زمینه خود\LTRfootnote{context window}، \LTRfootnote{contextualized}زمینه‌سازی می‌شود.
سپس توکن‌های کلیدی سیگنال‌های تقویت‌شده را دریافت می‌کنند، در حالی که توکن‌های کم اهمیت‌ سیگنال کاهش دریافت را می‌کنند. بردار زمینه پردازش بعدی را هدایت می‌کند.
ترانسفورمرها از توجه چند سر برای گرفتن جنبه‌های مختلف زمینه استفاده می‌کنند. هر یک از سر‌های توجه، الگوهای مختلفی را یاد می‌گیرد و توانایی مدل را برای توجه به ویژگی‌های مختلف افزایش می‌دهد.

ترانسفورمرها از اتصالات باقی مانده (الهام گرفته از \lr{ResNet}\cite{he2015deep}) برای کاهش مشکلات ناپدید شدن گرادیان استفاده می‌کنند. ترانسفورمرها در وظایف پردازش زبان طبیعی، از جمله ترجمه ماشینی، تجزیه و تحلیل احساسات، پاسخگویی به سوالات و تولید متن نتایج خوبی را از خود به نمایش گذاشته‌اند. مدل‌های قابل توجه عبارتند از \lr{BERT و GPT ،T5}.\cite{devlin2018bert}\cite{radford2018improving}\cite{t5} ترانسفورمرها در تشخیص تصویر، تشخیص اشیا و تقسیم بندی اجسام نیز به نتایج قابل توجه‌ای رسیده‌اند. به این مدل‌ها بینایی ترانسفورمر گفته می‌شود. این مدل‌ها همچنین در پردازش صدا، کارهای چندوجهی همانند ترکیب متن، تصویر و صدا و حتی مدل‌سازی مکانی-زمانی\LTRfootnote{spatio-temporal} استفاده می‌شوند.

\section{مدل زبانی بزرگ BERT}
\hspace{30pt}
نمایش‌های رمزگذار دوطرفه از ترانسفورمرها\LTRfootnote{Bidirectional Encoder Representations from Transformers}، که به اختصار برت \lr{BERT} نام‌گذاری شده است، یک مدل زبان مبتنی بر معماری ترانسفورمر فقط رمزگذار\LTRfootnote{encoder-only transformer model} است که توسط محققان گوگل در سال 2018 معرفی شد.\cite{devlin2018bert} این مدل به طور قابل توجه‌ای مدل‌های پیشرفته را در طیف گسترده‌ای از وظایف پردازش زبان طبیعی بهبود بخشیده است. در این بخش، ما به ریشه‌ها، معماری، و انواع از پیش آموزش دیده محبوب برت می‌پردازیم که برای این پژوهش استفاده شده‌اند.

طراحی برت از چندین مدل قبلی الهام گرفته است. بازنمایی‌های متنی \LTRfootnote{contextualized representations} بر خلاف مدل‌های سنتی مانند \lr{word2Vec} \cite{mikolov2013efficient} و \lr{GloVe}\cite{pennington2014glove}  روابط متنی \LTRfootnote{contextual relationships} را ثبت می‌کند. بر اساس کل جمله،  با در نظر گرفتن زمینه‌های چپ و راست، نگاشت‌های کلمه را \LTRfootnote{word embedding} ایجاد می‌کند.
برت روی مجموعه‌های متنی عظیم بدون حاشیه‌نویسی انسانی \LTRfootnote{human annotations} از قبل آموزش داده‌ شده \LTRfootnote{pre-trained} است. برت می‌تواند از متون خام یاد بگیرد و همچنین سازگار با کارهای مختلفی باشد که به وسیله یادگیری انتقالی دانش برت به آن‌ها انتقال پیدا می‌کند.

 معماری دوطرفه به برت اجازه می‌دهد تا در طول آموزش، توکن‌های قبلی و بعدی را در نظر بگیرد. این دوسویه بودن درک آن از زمینه را افزایش‌ می‌دهد. برت از یک معماری مبتنی بر ترانسفورمر و یک تکنیک جدید به نام آموزش دوطرفه استفاده می‌کند، که به مدل اجازه می‌دهد تا کل توالی ورودی را برای پیش‌بینی هر کلمه در متن در نظر بگیرد. برت از الگوریتم \lr{WordPiece}\cite{wu2016google} ،که مبتنی بر توکنیزه‌سازی زیرکلمه‌ای است،برای توکنیزه‌سازی استفاده می‌کند که در نسخه اصلی حجم واژگان آن برابر با سی‌هزار توکن یکتا می‌باشد.
برت اصلی بر روی دو کار از قبل آموزش دیده بود. مدل‌سازی زبان و پیش‌بینی جمله بعدی. بر روی مجموعه داده‌های بزرگ، از جمله \lr{Toronto BookCorpus} و ویکی‌پدیای انگلیسی  آموزش داده شده است.
برت از چهار جز‌‌ء اصلی ساخته و پرداخته شده است. اولین بخش، توکن‌ساز \lr{WordPiece} برای تبدیل کلمات به کدهای عدد صحیح می‌باشد. دوم لایه نگاشتگر  \LTRfootnote{embedding layer} توکن‌های رمزگذاری شده‌‌ای که یکی یک و مابقی صفر می‌باشند\LTRfootnote{one-hot vector} را به بردارهای پیوسته تبدیل می‌کند که نشان دهنده توکن‌ها هستند. سوم، پشته رمزگذارها که قلب برت هستند. رمزگذارها بر روی بردارهای نمایشی، تبدیلات را انجام می‌دهند و اطلاعات متنی را می‌گیرند و جزء چهارم، که لایه‌ی پاد نگاشتگر\LTRfootnote{un-embedding layer} است، بردارهای نمایش نهایی را دوباره به توکن‌های کدگذاری شده  تبدیل می‌کند.

\subsection{مشتقات برت}
\hspace{30pt}
طی چند سال اخیر مشتقات متعددی از معماری و الگوریتم برت ساخته شده است و بسیاری از آن‌ها به صورت رایگان در اختیار عموم قرار گرفته است. همچنین مدل‌های از پیش آموزش دیده متعددی چه از برت و چه از مشتقات آن در دسترس می‌باشد. در بخش‌های بعدی به این مدل‌ها می‌پردازیم.

\subsubsection{  مدل‌ از پیش آموزش دیده \lr{BERT-base-multilingual}  }
\hspace{30pt}
 \lr{BERT-base-multilingual-cased}\cite{bert-multilingual-cased}یک مدل قدرتمند و از پیش آموزش دیده است که توسط گوگل توسعه یافته است. این برنامه روی 104 زبان، از  جمله فارسی با داده‌های ویکی‌پدیا با هدف استفاده از مدل‌سازی زبان ماسک‌دار \LTRfootnote{Masked Language Modeling} آموزش دیده است. این مدل به حروف بزرگ و کوچک حساس است. این مدل از قبل بر روی مجموعه بزرگی از داده‌های چند زبانه به صورت خود نظارتی\LTRfootnote{self supervised} آموزش داده شده‌ است. این بدان معنی است که فقط بر روی متون خام بدون برچسب انسانی از قبل آموزش داده شده بود. این موضوع به مدل اجازه می‌دهد تا از حجم وسیعی از داده‌های در دسترس عموم استفاده کند.
همچنین در این پژوهش از نسخه غیر حساس به حروف کوچک و بزرگ با عنوان \lr{BERT-base-multilingual-uncased}\cite{bert-multilingual-uncased} نیز استفاده شده است. تفاوت این دو مدل صرفاً در حساسیت به حروف کوچک و بزرگ است. این موضوع باعث شده تا دایره لغات مدل حساس بزرگتر باشد.هر‌دو مدل، با دو هدف از قبل آموزش داده شده بود. مدل سازی زبان ماسک شده که شامل پوشاندن 15٪ از کلمات در ورودی، اجرای کل جمله ماسک شده در مدل و پیش بینی کلمات داده‌شده. پیش بینی جمله بعدی \LTRfootnote{Next Sentence Prediction}که شامل الحاق دو جمله نقابدار به عنوان ورودی در طول دوره قبل از آموزش است. سپس مدل پیش‌بینی می‌کند که آیا این دو جمله به دنبال یکدیگر هستند یا نه.
هدف این مدل در درجه اول تنظیم دقیق وظایفی است که از کل جمله برای تصمیم گیری استفاده می‌کنند، مانند طبقه بندی توالی\LTRfootnote{sequence classification}، طبقه بندی توکن\LTRfootnote{token classification} یا پاسخ به سؤال\LTRfootnote{question answering}.

\subsubsection{پارس برت}
\hspace{30pt}
\lr{bert-base-parsbert-uncased}\cite{parsbert}  یا پارس برت، یک مدل از پیش آموزش دیده است که به طور خاص برای درک زبان فارسی طراحی شده است. این مدل توسط آزمایشگاه هوشواره توسعه یافته است، بر اساس معماری برت گوگل است و تنظیمات مشابه برت اصلی دارد. این مدل بر روی یک مجموعه بزرگ فارسی با سبک‌های نوشتاری متنوع از موضوعات متعدد مانند مقالات علمی، رمان و اخبار از پیش آموزش داده شده است. این مجموعه که شامل بیش از 2 میلیون متن است، به صورت دستی جمع‌آوری شده است.

نسخه‌ی دیگری از پارس برت با عنوان \lr{bert-fa-zwnj-base}\cite{parsbert-zwnj} موجود است که بر روی یک مجموعه بزرگ فارسی که درنظر گرفتن کاراکتر نیم‌‌فاصله، با سبک‌های نوشتاری مقالات علمی، رمان و اخبار از پیش آموزش داده شده است. این مجموعه شامل بیش از ۹.۳ میلیون متن، 73 میلیون جمله و ۳.۱ میلیارد کلمه است، به صورت دستی جمع‌آوری شده.
به عنوان بخشی از متدولوژی پارس برت، یک پیش پردازش گسترده ترکیبی از برچسب‌گذاری اجزای کلام و تقسیم‌بندی \lr{WordPiece}
 برای آوردن مجموعه به یک قالب مناسب انجام شده است.

پارس برت بر اساس سه وظیفه پایین دستی\LTRfootnote{down stream task} پردازش زبان ارزیابی می‌شود. تجزیه و تحلیل احساسات\LTRfootnote{sentiment analysis}، طبقه بندی متن\LTRfootnote{text classification}، و شناسایی نهاد نامدار\LTRfootnote{named entity recognition}. این مدل  بین حروف بزرگ و کوچک تفاوتی قائل نمی‌شود و در حین آموزش، مانند برت چند زبانه 15 درصد از کلمات هر جمله به طور تصادفی پوشانده شده و سپس پیش‌بینی می‌شود.
 پارس برت از تمامی مدل‌های زبانی دیگر، از جمله برت چند زبانه و سایر مدل‌ها، در تمام کارهای ذکر شده، بهتر عمل کرده است. در نهایت می‌توان گفت پارس برت عملکرد پیشرفته‌ای را در مدل‌سازی زبان فارسی از خود نشان داده است و عملکرد برتر آن در وظایف مختلف پردازش زبان، اثربخشی و پتانسیل زیادی برای طیف گسترده‌ای از کاربردها نشان می‌دهد.



\subsubsection{RoBERTa}
\hspace{30pt}
\lr{RoBERTa} که توسط تیم هوش مصنوعی فیس بوک توسعه یافته است، یک مدل ترانسفورمر و گونه‌ای از برت مدلی است.\cite{liu2019roberta} هدف اولیه روبرتا فقط مدل‌سازی زبان ماسک‌دار و برخلاف برت، هدفی مبنی بر پیش‌بینی جمله بعدی ندارد. این مدل با مینی‌بچ‌ها\LTRfootnote{mini batch} و نرخ‌های یادگیری\LTRfootnote{learning rate} بسیار بزرگ‌تر آموزش می‌بیند. همچنین از یک نگاشتگر سطح بایت\LTRfootnote{‌byte-pair encoding} به عنوان توکنیزه‌ساز، مشابه \lr{GPT-2} استفاده می‌کند. این مدل بر روی مجموعه بزرگی از داده‌های انگلیسی به شیوه‌ای تحت خودنظارتی از قبل آموزش داده شده است و بدون برچسب انسانی از قبل آموزش داده شده است. فرآیند آموزش شامل یک هدف مدل‌سازی زبان ماسک‌دار  است، که در آن 15 درصد از کلمات هر جمله به‌طور تصادفی پوشانده شده و سپس پیش‌بینی می‌شوند. روبرتا در وظایف مختلف ارزیابی شده است. هدف اصلی آن تنظیم دقیق وظایفی است که از کل جمله برای تصمیم‌گیری استفاده می‌کنند، مانند طبقه‌بندی توالی و طبقه‌بندی توکن‌ها یا پاسخ‌گویی به سؤالات.

یکی از مدل‌های پیش‌آموزش دیده‌ی فارسی روبرتا \lr{robert-fa-zwnj-base}\cite{roberta-fa-zwnj-base} است. این مدل توسط آزمایشگاه هوشواره آموزش دیده است. داده آموزشی این مدل شامل ۳.۱ میلیار کلمه‌ای است که  \lr{bert-fa-zwnj-base} با آن آموزش دیده است. این مدل نیز همانند همتای برت خود، با درنظر گرفتن کاراکتر نیم فاصله آموزش دیده است. در این تحقیق از این نسخه از پیش آموزش دیده استفاده به عنوان نماینده روبرتا استفاده خواهیم‌ کرد.

\subsubsection{CharBERT}
\hspace{30pt}
CharBERT یک مدل زبانی از پیش آموزش دیده است که توسط \lr{Wentao Ma ،Yiming Cui ،Chenglei Si ،Ting Liu ،Shijin Wang} و \lr{Guoping Hu} توسعه داده شد و در مقاله‌ای با همین عنوان  ارائه شده است.\cite{Ma_2020}

مدل نگاشت‌های کلمه را برای هر توکن از نمایش‌های متوالی کاراکترها می‌سازد. سپس نمایش‌های کاراکترها و نمایش‌های زیرکلمه‌ای را با استفاده از یک ماژول تعامل ناهمگن جدید ترکیب می‌کند. این رویکرد با مشکل نمایش‌های ناقص و شکننده که هنگام تقسیم یک کلمه به واحدهای زیرکلمه‌ایی به وجود می‌آیند، مقابله می‌کند.
CharBERT بر روی وظایف مختلف پردازش زبان، از جمله پاسخ به سؤال، برچسب‌گذاری توالی و طبقه‌بندی متن، ارزیابی می‌شود.
علاوه بر این، CharBERT برای برنامه‌هایی مانند شناسایی آدرس وب‌سایت مخرب استفاده شده است. با استخراج ویژگی‌های سلسله مراتبی و اعمال توجه لایه‌آگاه\LTRfootnote{layer aware} و ادغام هرم فضایی\LTRfootnote{integration of the spatial pyramid
}، چارچوبی کارآمد برای چنین وظایفی فراهم می‌کند.

متاسفانه نسخه از پیش آموزش دیده‌ای که روی زبان فارسی آموزش دیده باشد وجود ندارد. در نتیجه از نسخه آموزش دیده charbert-roberta-wiki \cite{charbert-roberta-wiki} که بر روی روبرتا با استفاده از داده‌های ویکی پدیای انگلیسی آموزش دیده استفاده خواهیم کرد.
\chapter{مروری بر کار‌های پیشین}
\hspace{30pt}
این فصل  مروری جامع از ادبیات موجود در زمینه مطالعه ارائه می‌دهد. این موضوع به زمینه‌سازی تحقیق در چشم انداز گسترده‌تر آکادمیک کمک می‌کند و نشان می‌دهد که چگونه این پژوهش در گفتمان جاری قرار می‌گیرد. در این فصل بررسی تعدادی از مطالعات، ارائه می‌شود. هدف آن آشنا کردن خواننده با کار‌هایی است که در زمینه نیم‌فاصله و فاصله قرار می‌گیرد.

بیشتر کارهای انجام شده در این زمینه، مربوط به تقسیم‌بندی کلمات\LTRfootnote{word segmentation} هستند. از آن‌جایی که فاصله نشانه‌ای از محل جدا‌سازی کلمات است، تشخیص فاصله همپوشانی زیادی با تقسیم‌بندی کلمات دارد. از طرفی نیم‌فاصله که در داخل کلمات استفاده می‌شود و شامل تقسیم‌بندی مورد نظر نمی‌شود. در نتیجه تقسیم‌بندی کلمات شامل همه‌ حالت‌های ما از جمله فاصله‌گذاری عدم فاصله‌گذاری می‌شود. تنها موضوعی که تقسیم‌بندی کلمات آن را پوشش نمی‌دهد، قراردادن نیم‌فاصله در جای مناسب است. تقسیم‌بندی کلمات یک وظیفه اساسی در پردازش زبان طبیعی است و نقش مهمی در زمینه‌های مختلف مانند بازیابی اطلاعات، برچسب‌گذاری اجزای کلام، شناسایی موجودیت نام دار و تجزیه و تحلیل احساسات ایفا می‌کند.
\section{تقسیم‌بندی کلمات اردو با استفاده از رویکردهای یادگیری ماشینی}
\hspace{30pt}
این مقاله توسط صدیق نواز خان و همکاران، یک رویکرد مبتنی بر یادگیری ماشینی را برای تقسیم‌بندی کلمات اردو ارائه می‌کند. نویسندگان از فیلدهای تصادفی شرطی \lr{(CRF)}\LTRfootnote{Conditional Random Fields} برای دستیابی به این کار استفاده کرده‌اند.\cite{khan2018urdu}
 تقسیم‌بندی کلمات اردو به دلیل مسائلی مانند مشکل درج فاصله و مشکلات حذف فاصله یک کار چالش برانگیز است. در حالی که ابزارها و منابع توسعه‌یافته برای تقسیم‌بندی واژه‌های انگلیسی و سایر زبان‌های غربی عملکردی بسیار عالی دارند، بسیاری از زبان‌ها، از جمله اردو، مرزبندی مناسبی بین کلمات ندارند. هدف این کار پژوهشی، غلبه بر چنین چالش‌هایی در متن اردو با استفاده از روش‌ یادگیری ماشینی است.

\section{ پارسی‌پرداز(ParsiPardaz)}
\hspace{30pt}
پارسی پرداز یک ابزار پردازش زبان فارسی است. مجموعه‌ای از ابزارها و منابع را برای پردازش متن فارسی فراهم می‌کند که شامل وظایفی مانند تقسیم‌بندی کلمات می‌باشد. تقسیم‌بندی واژه‌ها در فارسی به دلیل مسائلی مانند مشکل درج فاصله و مسائل حذف فاصله، یک کار چالش برانگیز است.
پارسی پرداز به مشکلات تقسیم‌بندی کلمات و تشخیص نیم‌فاصله در زبان فارسی می‌پردازد که به صورت مشترک به عنوان مسئله برچسب‌گذاری توالی مورد بررسی قرار می‌گیرند. \cite{sarabi2013parsipardaz}

\section{ پارسی‌ور(ParsiVar)}
\hspace{30pt}
پارسی‌ور نیز یک مجموعه‌ای از ابزار برای پردازش زبان فارسی است که تقسیم‌بندی کلمات نیز جز وظایف این مجموعه است. پارسی‌ور در مشکلات تقسیم‌بندی واژه‌ها و تشخیص نیم‌فاصله در زبان فارسی، رویکردی مشابه پارسی‌پرداز دارد و از برچسب‌زنی توالی برای این کار استفاده می‌کند. پارسی‌ور ابزار جامعی برای پردازش زبان فارسی است و دارای موارد کاربردهای وسیعی است.

از پارسی‌ور می‌توان برای نرمال سازی متون فارسی در قالب استاندارد استفاده کرد. این ویژگی در تهیه داده‌ها برای کارهای پردازش زبان مفید است. پارسی‌ور ابزارهایی برای نشانه‌گذاری کلمات و جملات ارائه می‌دهد. این یک گام اساسی در بسیاری از وظایف پردازش زبان، مانند طبقه‌بندی متن، تجزیه و تحلیل احساسات و ترجمه ماشینی است. پارسی‌ور می‌تواند کلمات را با جزء کلام خود برچسب‌گذاری کند و تجزیه کم عمق جملات را انجام دهد. این ویژگی‌ها در کارهایی مانند شناسایی موجودیت نامدار و استخراج رابطه مفید هستند. پارسی‌ور شامل غلط‌گیر املایی است که می‌توان از آن برای تصحیح غلط‌های املایی در متون فارسی استفاده کرد. پارسی‌ور ابزارهایی را برای تصحیح فاصله بین یا درون کلمات ارائه می‌دهد که این امر در زبان فارسی اهمیت ویژه‌ای دارد.

علاوه بر این، پارسی‌ور در پروژه‌های تحقیقاتی مختلف و کاربردهای دنیای واقعی از جمله سیستم‌های بازیابی اطلاعات، سیستم‌های ترجمه ماشینی و سیستم‌های طبقه‌بندی متون استفاده شده‌است. همچنین از این مجموعه در توسعه یک سیستم تشخیص سرقت ادبی فارسی استفاده شده است.\cite{mohtaj2018parsivar}



\section{ هضم(Hazm)}
\hspace{30pt}
هضم یک کتابخانه در زبان برنامه نویسی پایتون است که برای وظایف پردازش زبان طبیعی در متن فارسی طراحی شده است. این کتابخانه ویژگی‌های مختلفی برای تجزیه و تحلیل، پردازش و درک متن فارسی ارائه می‌دهد.
هضم به مشکلات تقسیم‌بندی کلمات و تشخیص نیم‌فاصله در زبان فارسی رویکرد برچسب گذاری توالی دارد. در این بخش برخی از ویژگی‌های اصلی هضم آورده شده است:
\begin{enumerate}
    \item نرمال‌سازی\LTRfootnote{normalization}: متن را به یک فرم استاندارد مانند از بین بردن حرکه، تصحیح فاصله و غیره تبدیل می‌کند.
     \item توکنیزه‌سازی\LTRfootnote{tokenization}: متن را به جملات و کلمات تقسیم می‌کند.
      \item لماتایز سازی\LTRfootnote{lemmatization}: کلمات را به شکل پایه آن‌ها کاهش می‌دهد.
       \item  برچسب زدن اجزای کلام\LTRfootnote{part of speech tagging}: بخشی از گفتار را به هر کلمه اختصاص می‌دهد.
        \item تجزیه وابستگی\LTRfootnote{dependency parser}: روابط نحوی بین کلمات را مشخص می‌کند.
         \item نگاشتگری\LTRfootnote{embedding}: بازنمایی بردار از کلمات و جملات ایجاد می‌کند.
          \item خواندن بدنه‌های فارسی: بسیاری از بدنه‌های فارسی را با کدهای آماده می‌خواند و قابل استفاده می‌کند.
\end{enumerate}

هضم در کارهای مختلف پردازش زبان ارزیابی شده است و به عملکرد بالایی رسیده است. این برنامه به طور گسترده در پروژه‌های تحقیقاتی و برنامه‌های دنیای واقعی‌، از جمله سیستم‌های بازیابی اطلاعات، سیستم‌های ترجمه ماشین و سیستم‌های طبقه بندی متن مورد استفاده قرار می‌گیرد.\cite{hazm}

\section{تصحیح فاصله‌ها در جملات فارسی برای توکنیزه‌سازی}
\hspace{30pt}
مقاله تصحیح فاصله‌ها در جملات فارسی برای توکنیزه‌سازی نوشته مهناز پناهنده و شیرین قنبری، در سال ۲۰۱۹ منتشر‌شده است و به مشکل استفاده نادرست از فاصله‌ها در متن فارسی می‌پردازد که موضوعی قابل توجه برای توکنیزه‌سازی متن‌ها است.

نویسندگان روشی قانون محور برای شناسایی و تصحیح جداسازی کلمات و تصحیح فاصله‌ها پیشنهاد می‌کنند. این روش، شامل نرمال‌سازی متن است که شامل تصحیح فاصله‌ها است.  نویسندگان مجموعه‌ای از نظرات کاربران را در خدمات رسانه‌های اجتماعی برای مطالعه خود جمع آوری کرده‌اند. این نظرات احتمالاً حاوی نمونه‌های مختلفی از تقسیم‌بندی نادرست کلمات و استفاده نادرست از فاصله‌ها هستند، که مجموعه داده‌‌ی چالش برانگیزی را برای یادگیری مدل فراهم می‌کند.

این روش شامل آموزش مدلی بر روی این مجموعه‌ای از داده‌ها، از جمله بدنه بیژن‌خان، با هدف یادگیری تصحیح خطاهای تقسیم‌بندی کلمات و تشخیص استفاده صحیح از فاصله‌ها بوده است. سپس مدل بر اساس توانایی آن در تصحیح این خطاها در داده‌های دیده نشده مورد ارزیابی قرار گرفته‌است.

نویسندگان گزارش می‌دهند که آن‌ها به میانگین کلان امتیاز \lr{ 81.94٪ F1}دست یافته‌اند. این نتایج نشان می‌دهد، روش آن‌ها به طور قابل توجه‌ای عملکرد ابزارهای پیش پردازش پیشرو را بهبود بخشیده است و رویکرد آن‌ها در پرداختن به چالش‌های تقسیم‌بندی کلمات و تصحیح فاصله‌ در فارسی موفق بوده است.\cite{Panahandeh2019CorrectionOS}


\section{تصحیح تقسیم‌بندی واژه‌های فارسی به هم چسبیده و تشخیص نیم‌فاصله با استفاده از برت}
\hspace{30pt}
مقاله «تصحیح تقسیم‌بندی واژه‌های فارسی به هم چسبیده و تشخیص نیم‌فاصله با استفاده از برت» توسط احسان دوست محمدی، مینو نساجیان و عادل رحیمی، در سال ۲۰۲۰ منتشر‌شده و الهام‌بخش اصلی این پژوهش بوده است. این مقاله، رویکرد جدیدی را برای مقابله با چالش‌های تقسیم‌بندی کلمات و شناخت نیم‌فاصله در زبان فارسی ارائه می‌کند.

تقسیم‌بندی واژه‌ها در فارسی به دلیل مشکلاتی مانند مشکل درج فاصله و حذف فاصله، یک کار چالش برانگیز است. نیم‌فاصله یک کاراکتر غیرچاپی است که در املای چند زبان از جمله فارسی استفاده می‌شود. نویسندگان به طور مشترک به این مسائل به عنوان یک مسئله برچسب‌گذاری توالی برخورد می‌کنند. آن‌ها از مدل برت یک تکنیک یادگیری ماشینی مبتنی بر ترانسفورمر برای پردازش زبان طبیعی، برای مقابله با این مسائل استفاده می‌کنند.

نویسندگان مجموعه ای از 500 جمله با سطح دشواری بالا را برای مطالعه خود جمع آوری کرده‌اند. این جملات احتمالاً حاوی نمونه‌های مختلفی از تقسیم‌بندی نادرست کلمات و استفاده نادرست از نیم‌فاصله هستند که مجموعه داده‌ای چالش برانگیز را برای یادگیری مدل فراهم می‌کنند.

این روش شامل آموزش مدل برت چند‌زبانه بر روی این مجموعه داده بود، با هدف یادگیری تصحیح خطاهای تقسیم‌بندی کلمات و تشخیص استفاده صحیح از نیم‌فاصله. سپس مدل را بر اساس توانایی آن در تصحیح این خطاها در داده‌های دیده نشده مورد ارزیابی قرار داده‌اند. نویسندگان گزارش می‌دهند که آن‌ها توانسته‌اند به میانگین کلان امتیاز \lr{F1 92.40٪} در مجموعه داده‌‌های خود دست یابند. \cite{doostmohammadi-etal-2020-joint}
\chapter{پژوهش پیشنهادی}
فصل چهارم شامل هسته‌ى تحقیق این پایان‌نامه می‌باشد. این فصل شامل چند بخش است که یک به یک به آن‌ها خواهیم پرداخت. بخش اول به نحوه‌ی جمع آوری داده‌ها، روش‌های پاکسازی و آماده‌سازی آن‌ها و همچنین به نحوه‌ی ارائه‌ی آن‌ها به مدل‌ها می‌پردازیم تا با تمام جوانب موجود در مورد داده‌هایی که به مدل‌ها ارائه می‌شوند‌، آشنا شویم. در بخش دوم به مدل‌ها می‌پردازیم و همراه با روند پژوهش، کار‌های انجام شده را بررسی می‌کنیم. در بخش پایانی به انتشار مدل و فرآیند بهره برداری از مدل‌های آموزش دیده برای تصحیح فاصله و نیم‌فاصله می‌پردازیم.


\section{داده‌}
\hspace{30pt}
داده‌های ما شامل دو بدنه‌ی بیژن‌خان\cite{bijankhan} با دو و نیم میلیون کلمه و بدنه‌ی پیکره\cite{peykareh} شامل ده و نیم میلیون کلمه می‌باشند که در مجموع، با توجه به اینکه آموزش در سطح کاراتر انجام می‌شود، بیش از شصت میلیون کاراکتر را برای ما به همراه دارد که حجم داده‌ی قابل قبولی برای تنظیم مدل‌های ترانسفورمر مهیا می‌کند. این بدنه‌ها به چند دلیل انتخاب شده‌اند. دلیل اول تصحیح آن‌ها در بالاترین سطح توسط اشخاص و نهاد‌های با اعتبار بالاست، چرا که اعتبار داده‌های مورد استفاده با کارایی نتیجه پژوهش در کار‌های دنیای واقعی ارتباط مستقیم دارد. دلیل حساسیت این موضوع به این است که فرضاً اگر بتوانیم مدلی بی‌نقص طراحی کنیم و آن را آموزش دهیم کیفیت خروجی آن نمی‌تواند بهتر از داده ورودی باشد. دلیل دوم استفاده‌ی کار‌های پیشین از بدنه اصلی ما، یعنی پیکره و درنظر گرفتن آن به عنوان داده‌ی معیار است. با انتخاب پیکره و بیژن‌خان که شباهت زیادی به پیکره دارد می‌توانیم در فضایی نزدیک به کار‌های پیشین فعالیت خود را تعریف کنیم.

داده‌های هر دو بدنه به صورت تقسیم‌شده به کلمات، به همراه برچسب اجزای کلام موجود هستند. این داده‌ها به صورت جملات مجزا تقسیم‌بندی نشده‌اند. اولین کاری که بر روی آن‌ها انجام می‌دهیم این است که داده‌ها را به شکل‌ ساخت یافته‌ای تبدیل کنیم که برای پژوهش ما و همچنین کارهای مشابه دیگر قابل استفاده باشند. شرح آن در زیربخش اول، پیش‌پردازش موجود است. در زیربخش دوم فرآیند برچسب گذاری و متناظر‌سازی ارائه می‌شود. در زیر بخش طراحی دیتاست مناسب مدل، به‌ نحوه ساخت دیتاست مناسب برای آموزش مدل را بررسی می‌کنیم، سپس به آمارهای مربوط به بدنه‌ها می‌پردازیم که به ما در فهم بهتر داده‌های ما کمک می‌کنند.
\subsection{پیش پردازش}
\hspace{30pt}
در پیش پردازش، داده‌ها در وهله اول به شکل یک لیست بلند از توکن‌ها ذخیره شده‌اند. هدف ما در این بخش رسیدن به چهار نوع داده‌ی ساخت‌یافته است. اول به صورت یک متن کامل، دوم به صورت لیستی از توکن‌ها، سوم به صورت لیستی از جملات و چهارم به صورت لیستی از توکن‌های هر جمله به شکل لیست دو بعدی. این چهار نوع داده ارزش بالایی دارند. محصول این پیش پردازش می‌تواند در بسیاری از مدل‌های خود نظارتگر استفاده شود.

در ابتدا پس از پاکسازی داده‌ها به لیستی از کل توکن‌های موجود رسیدیم. با به هم پیوستن توکن‌ها با یک فاصله میان آن‌ها جملات را ساختیم. سپس با استفاده از عبارات با قاعده، داده را از مشکلاتی از قبیل فاصله قبل از نقطه، و هر نوع فاصله‌گذاری نادرست قبل یا بعد علائم اشاره را حل کردیم. به این ترتیب داده‌های نوع اول و دوم ما مهیا شدند.

برای تمییز دادن جملات از یکدیگر چند روش امتحان شد. از جمله این روش‌ها  می‌توان به جداسازی جملات توسط نقطه، علامت تعجب و علامت سوال اشاره کرد. در نهایت تمام جملات به صورت دستی با کمک عبارات با قاعده جدا شدند. این جملات به صورت توکنیزه تمییز داده‌ شدند و از این داده لیست جملات و لیست جملات توکنیزه‌ استخراج شد. لیست جملات علاوه بر این شامل تصحیح دستی فاصله نیز شدند. تا دقت ما دوچندان شود.
\subsection{برچسب‌گذاری}
\hspace{30pt}
یکی از کارهای مهم در تهیه داده، برچسب‌گذاری آن است.  از آن‌ جایی که مدل ما برچسب‌گذار توالی است اهمیت این موضوع دو چندان است. برای این منظور، برچسب‌گذاری، در سطح کاراکتر طراحی و ساخته شد که به وسیله‌ی عبارات با قاعده برچسب‌گذاری را انجام‌ دهد. برچسب‌زن ما به شکلی طراحی شده است که هر عنصری را در سطح کاراکتر با رعایت دو محدودیت می‌تواند برچسب بزند. قبل از توضیح محدودیت‌ها لازم است که به نحوه کار برجسب‌گذار بپردازیم.

برجسب‌گذار ابتدا به همه‌ی کاراکتر‌ها برچسب صفر می‌دهد که به معنی نداشتن برچسب شاخص است. سپس با استفاده از عبارات با قاعده کل متن را بررسی کرده و برچسب متناظر هر کاراکتری که برای ما اهمیت دارد را در جای درست، قرار می‌دهد. پس از آن کل برچسب‌ها یک واحد به عقب می‌روند. به این معنی که برچسب هر کاراکتر به کاراکتر یکی قبل از خود الصاق می‌شود. این موضوع فقط در قالب برچسب‌گذاری توالی می‌تواند معنی پیدا کند و به این معنی است که کاراکتر بعدی ما چنین برچسبی باید داشته باشد. در نهایت تمام کاراکتر‌های با برچسب غیر صفر می‌توانند از داده‌ها برداشته شوند.

این نوع برجسب‌گذاری شامل دو محدودیت است. اول برچسب‌های غیر صفر متوالی اتفاق نیفتند و دوم برچسب‌ها هم‌پوشانی نداشته باشند و هیچ کاراکتری دو برچسب دریافت نکند. با رعایت این محدودیت‌ها، برجسب‌گذار ما قابلیت برچسب زدن هر نوع داده‌ی متوالی را دارد.

کارکرد این برچسب‌گذار در این پژوهش تقریبا متناسب با کارکرد اصلی آن است. ابتدا به ازای همه‌ی حروف و علامت‌ها برچسب «صفر» قرار می‌گیرد. سپس به ازای هر یک از کلاس‌ها، در صورت مشاهده فاصله «یک» و در صورت مشاهده نیم‌فاصله «دو» در برچسب یکی قبل از برچسب متناظر کاراکتر قرار می‌گیرد. دليل این نوع برچسب گذاری خاصیت متوالی داده‌ی ورودی مدل است. سپس در مرحله ی بعدی تمام کاراکترهای کلاس غیر از صفر، به همراه برچسب متناظر آن‌ها از داده‌ها حذف می‌شوند. خروجی این فرآیند به ازای هر متن شامل دو لیست کاراکترها و برچسب‌ها خواهد بود. شکل \ref{fig:space_labeler} نشان دهنده‌ی فرآیند برچسب‌گذاری یک جمله کوتاه است.
\begin{figure}[H]
      \centering
      \includegraphics[width=1\linewidth]{Figures/f03-space_labeler.jpg}
      \caption{شیوه برچست‌گذاری توکن‌های کاراکترها}
      \label{fig:space_labeler}
  \end{figure}
\subsection{دیتاست مناسب مدل}
\hspace{30pt}
برای اینکه داده‌ی ما قابل ارائه به مدل‌ها باشد لازم است که داده در دیتاست‌های به خصوصی ذخیره شود. داده‌های هر دو بدنه در یک دیتاست تجمیع شدند و پس از برهم زدن آن‌ها دیتاست نهایی برای تمام مدل‌ها ساخته شد که شامل سه بخش آموزش\LTRfootnote{training}، آزمون\LTRfootnote{testing} و راستی آزمایی\LTRfootnote{validation} شد. 80 درصد داده‌های ما در بخش آموزش قرار گرفتند و هر کدام از  بخش‌های آزمون و راستی آزمایی شامل 10 درصد از کل داده‌ها شدند. در نتیجه داده آموزش راستی آزمایی و آزمون تمام مدل‌ها با هم برابر است.

داده‌ها قبل از ارائه به مدل نیازمند تغییر کاراکترها به اعداد شاخص ورودی و پوشال‌گذاری\LTRfootnote{padding} داده نیز هستند. پس با استفاده از این دیتاست، دیتاستی برای هر یک از مدل‌ها ساخته شده که هر یک از سه بخش دایتاست را با تغییراتی در خود قرار می‌دهند.

داده به صورت لیستی از جملات بارگذاری می‌شود و بعد از تبدیل به اعداد مفهوم برای مدل به همراه تگ‌های اضافی مشخص کننده اول و آخر جمله، جملات به صورت پشت سر هم در لیست قرار می‌گیرند که نهايتاً به قسمت‌های مساوی تقسیم می‌شود تا مدل از روی آن‌ها یادگیری را انجام دهد. تمام مدل‌ها در قسمت‌های ۵۱۲ تایی آموزش را انجام می‌دهند. آخرین بخش هم برای رسیدن به اندازه استاندارد با تگ‌های پوشال‌گذاری پر می‌شود تا اندازه آن به ۵۱۲ برسد. این روش شامل کمترین تعداد پوشال‌گذاری است، چراکه فقط در بخش آخر داده پوشال وجود خواهد داشت و مطمئناً تعداد کل پوشال‌ها کمتر از ۵۱۲ خواهد بود. این موضوع به سرعت آموزش کمک زیادی می‌کند و زمان آموزش را کوتاه‌تر می‌کند.


\subsection{آمار‌های مرتبط}
\hspace{30pt}
با توجه به حجم عظیم داده‌ها، آمار‌های مرتبط به داده می‌توانند کمک شایانی به فهم آن‌ها بکنند در ادامه با تعدادی از آمار‌های مربوط داده‌های بدنه بیژن‌خان و همچنین بدنه پیکره آشنا می‌شویم این آمار‌ها شامل تعداد کاراکترها جملات و توکن‌ها، نسبت‌های تعداد کاراکتر به تعداد توکن، کاراکتر به جمله و توکن به جمله هستند. در ادامه میانگین تعداد فاصله در جملات، میانگین تعداد نیم‌فاصله در جملات و در نهایت نسبت فاصله به باقی کاراکترها و نسبت نیم‌فاصله به باقی کاراکترها.
\begin{table}[H]
    \centering
     \caption{آمار‌هایی از داده‌های استفاده‌ شده در پژوهش}
    \label{tab:data_statistics}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{معیار}                                  & \textbf{بیژن‌خان} & \textbf{پیکره} & \textbf{همه} \\ \hline
تعداد کاراکتر‌ها                                & \(12.4m\)         & \(48.0m\)      & \(60.4m\)    \\ \hline
کل توکن‌ها                                      & \(2.5m\)          & \(10.1m\)      & \(12.7m\)    \\ \hline
تعداد جمله‌ها                                   & \(88255\)         & \(335926\)     & \(424181\)   \\ \hline
نسبت کارکتر بر توکن                             & \(4.77\)          & \(4.75\)       & \(4.76\)     \\ \hline
نسبت کارکتر بر جمله                             & \(140.5\)         & \(143\)        & \(142.5\)    \\ \hline
نسبت توکن بر جمله                               & \(29.43\)         & \(30.07\)      & \(29.93\)    \\ \hline
نسبت فاصله بر جمله                              & \(26.64\)         & \(26.97\)      & \(26.90\)    \\ \hline
نسبت نیم‌فاصله بر جمله                          & \(1.948\)         & \(2.082\)      & \(2.054\)    \\ \hline
\multicolumn{1}{|l|}{نسبت فاصله بر کاراکتر}     & \(0.19\)          & \(0.189\)      & \(0.189\)    \\ \hline
\multicolumn{1}{|l|}{نسبت نیم‌فاصله بر کاراکتر} & \(0.014\)         & \(0.015\)      & \(0.014\)    \\ \hline
\end{tabular}

\end{table}

\section{مدل}
\hspace{30pt}
در فصل دوم به مدل‌های از پیش آموزش دیده‌ای که در این پژوهش استفاده شده‌است پرداختیم. مدل‌های ما شامل سه معماری مختلف هستند. معماری برت\LTRfootnote{BERT}، روبرتا\LTRfootnote{RoBERTa} و کربرت\LTRfootnote{CharBERT}. هدف اصلی این مدل‌ها برچسب‌گذاری توالی نیست ولی هدف ما، استفاده از این مدل‌ها در برچسب‌گذاری توالی به وسیله‌ی یادگیری انتقالی است. مدل‌های ما بخش بزرگی از معماری خود را از مدل‌های از پیش آموزش دیده به ارث می‌برند. علاوه بر معماری‌های ذکر شده، مدل‌های ما لایه‌ای برای کلاس‌ بندی کاراکتر‌ها در متن دارند که کار کلاس بندی نهایی مدل را انجام می‌دهد. این لایه، خروجی مدل از پیش آموزش دیده را در قالب  768 ویژگی دریافت می‌کند و خروجی خود را در قالب ۳ لوجیت\LTRfootnote{logit} به ازای هر یک از کلاس‌های احتمالی، برمی‌گرداند. این لایه تابع فعال ساز خطی دارد و شامل عرض از مبدا نیز هست.  این لایه بین تمام مدل‌های ما مشترک است و همین باعث می‌شود که مقابسه‌ی مدل‌های نهایی فقط بر اساس معماری و وزن‌های مدل‌های از پیش آموزش دیده باشد.
 تنظیماتی که مدل‌ها با استفاده از آن‌ها آموزش دیده‌اند نیز در همه مدل‌ها با هم برابر هستند. این مدل‌ها در ۱۰ ایپاک با نرخ یادگیری\LTRfootnote{learning rate} 00002.0 با اندازه دسته آموزشی\LTRfootnote{train batch size} ۸ و گرادیان تجمعی\LTRfootnote{gradient accumulation} ۸ که در نتیجه اندازه دسته‌ی آموزشی موثر\LTRfootnote{effective batch size} را برابر ۶۴ می‌کند آموزش دیده اند. راستی آزمایی مدل‌ها هر هزار قدم انجام شده و مدل نهایی، بهترین مدلی است که از بین مدل‌های راستی آزمایی شده‌، انتخاب شده‌است.

مدل‌ها بر روی  کارت گرافیکی \lr{nvidia RTX 3050 Mobile} با ظرفیت ۴ گیگابایت رم، و ۴ گیگ حافظه مبادله و پردازنده مرکزی \lr{Intel corei7 11370H}  با ۱۲ مگابایت کش و ۱۶ گیگابایت حافظه اصلی، آموزش دیده‌اند. این مدل‌ها زمان آموزش بسیار نزدیکی داشتند. میانگین زمان اجرا ۵۵ ساعت و ۲۵ دقیقه بوده است.

\begin{table}[H]
 \centering
     \caption{مدت زمان آموزش مدل‌ها}
    \label{tab:model_times}
\begin{tabular}{|lc|}
\hline
\multicolumn{1}{|c|}{\textbf{مدل}} & \textbf{مدت زمان آموزش}  \\
\hline
bert-multilingual-uncased          & $55:12$                  \\
\hline
bert-multilingual-cased            & $55:01$                  \\
\hline
parsbert-uncased                   & $55:32$                  \\
\hline
bert-fa-zwnj-base                  & $55:38$                  \\
\hline
roberta-fa-zwnj-base               & $55:47$                  \\
\hline
charbert-roberta-wiki              & $55:15$                  \\
\hline
\end{tabular}
\end{table}
\section{انتشار}
\hspace{30pt}
یکی دیگر از کارهای انجام شده انتشار محصولات این پژوهش می‌باشد به این محصولات در فصل نتایج پرداخته خواهد شد در اینجا صرفاً قصد داریم تا با نحوه انتشار آن‌ها آشنا شویم. داده‌های حاصل از این پژوهش در دیتاست‌هایی جمع‌آوری شدند و بر روی پلتفرم \lr{Hugging Face Hub} قرار گرفته‌اند تا در اختیار همگان باشند. برچسب‌گذار و پیش‌پردازشگر ما نیز بر روی پلتفرم \lr{GitHub} قرار گرفته‌اند. مدل‌های آموزش دیده نیز بر روی پلتفرم  \lr{Hugging Face Hub} به اشتراک گذاشته شدند. وب‌سایتی طراحی و ساخته شد که با استفاده از مدل‌های ما کار تصحیح فاصله و نیم‌فاصله را انجام می‌دهد. وظیفه اصلی این وب‌سایت اجرای تصحیح‌های مورد نظر بر روی متن‌های کاربران است. هدف از ساخت چنین وب‌سایتی در دسترس قرار دادن نتایج این پژوهش می‌باشد.

\chapter{نتایج}
\hspace{30pt}
فرآیند انجام این پژوهش با نظر به کارایی و کاربرد قسمت‌های مختلف آن صورت گرفته‌است. به همین دلیل در هر یک از بخش‌ها، تلاش مضاعفی برای تبدیل آن، به محصولی مجزا شده‌است. این محصولات شامل داده‌های پردازش شده، پیش‌پردازشگر، برچسب‌گذار، مدل‌ها و سامانه‌ای برای استفاده عموم از تصحیح کننده فاصله زبان فارسی هستند. در این فصل با هر یک از این محصولات آشنا می‌شویم.

\section{داده}
\hspace{30pt}
یکی از کار‌های مهمی که باید انجام می‌شد، ارزیابی کیفیت فاصله‌گذاری در بدنه‌ها می‌باشد. هزار جمله از هر یک از بدنه‌ها انتخاب شد و با توجه به قوانین فرهنگستان زبان فارسی مورد تصحیح قرار گرفت، این تصحیح‌ها در سه مرحله توسط سه نفر انجام گرفت که نتیجه برآیند آن‌ها به عنوان داده معیار قرار گرفت و بدنه‌ها به وسیله این داده‌های تصحیح شده، مورد ارزیابی قرار داده شدند.
\begin{table}[H]
\centering
\caption{نتایج ارزیابی بدنه بیژن خان}
 \label{tab:bijankhan metrics}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{5}{|c|}{\textbf{بدنه بیژن‌خان}}                                                                                                                                                                         \\
\hline
\textbf{کلاس}           & \multicolumn{1}{l|}{\textbf{دقت (precision)}} & \multicolumn{1}{l|}{\textbf{صحت (recall)}} & \multicolumn{1}{l|}{\textbf{درستی (accuracy)}} & \multicolumn{1}{l|}{\textbf{\LR{F1-score}}}  \\
\hline
\textbf{صفر (همه)}      & $0.9921$                                      & $0.9998$                                   & $0.9940$                                       & $0.9959$                                     \\
\hline
\textbf{یک (فاصله)}     & $0.9996$                                      & $0.9979$                                   & $0.9994$                                       & $0.9988$                                     \\
\hline
\textbf{دو (نیم‌فاصله)} & $0.9832$                                      & $0.7571$                                   & $0.9939$                                       & $0.8555$                                     \\
\hline
\end{tabular}

\end{table}


\begin{table}[H]
\centering
\caption{نتایج ارزیابی بدنه پیکره}
\label{tab:peykareh_metrics}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{5}{|c|}{\textbf{بدنه پیکره}}                                                                                                                                                                            \\
\hline
\textbf{کلاس}           & \multicolumn{1}{l|}{\textbf{دقت (precision)}} & \multicolumn{1}{l|}{\textbf{صحت (recall)}} & \multicolumn{1}{l|}{\textbf{درستی (accuracy)}} & \multicolumn{1}{l|}{\textbf{\lr{F1-score}}}  \\
\hline
\textbf{صفر (همه)}      & $0.9942$                                      & $0.9997$                                   & $0.9956$                                       & $0.9970$                                     \\
\hline
\textbf{یک (فاصله)}     & $1.0$                                         & $0.9996$                                   & $0.9999$                                       & $0.9998$                                     \\
\hline
\textbf{دو (نیم‌فاصله)} & $0.9924$                                      & $0.875$                                    & $0.9955$                                       & $0.9300$                                     \\
\hline
\end{tabular}

\end{table}


بیشترین تعداد اشتباه‌ها، عدم نیم‌فاصله‌گذاری بودند که در معیار‌های به دست آمده مشهود است. اکثر این مشکلات، در بعد از کلماتی است که به کلمه بعدی متصل نمی‌شوند. به عنوان مثال «زیبا‌تر» یا «پرها» یا پسوند‌هایی مثل (ها، تر،پر). مابقی اشکلات در حدی بودند که می‌توان از آن‌ها چشم‌پوشی کرد.
نتایج ارزیابی، اطمینان خاطر نسبی برای درستی انتخاب این دو بدنه به عنوان داده‌های این پژوهش، به ما داده‌اند.
\section{دیتاست}
\hspace{30pt}
همانطور که قبلاً اشاره کردیم، در این پژوهش از بدنه‌های پیکره و بیژن‌خان استفاده کرده‌ایم. با توجه به ارزش بالای این دو بدنه استفاده کردن از آن‌ها شامل چالش‌های وقت‌گیری است که می‌تواند فرآیند پژوهش‌هایی را که از این بدنه‌ها استفاده می‌کنند، کند نماید و آن‌ها را به تعویق بیاندازد. پس تلاش کردیم تا به وسیله تکنولوژی‌های جدید بتوانیم ساختار بدنه‌ها را بهبود ببخشیم. برای این منطور دیتاست جدیدی برای هر یک از بدنه‌ها تعریف کردیم که با استفاده از تکنولوژی \lr{PyArrow} ساخته شده‌اند و ساختاری همانند یکدیگر دارند. \lr{PyArrow} یک کتابخانه منبع باز است که یک رابط بین زبانی برای کار با داده‌های درون حافظه فراهم می‌کند. این پروژه که توسط \lr{Apache Arrow} توسعه یافته است. این کتابخانه در جامعه پردازش داده به دلیل توانایی آن در مدیریت
کارآمد داده‌های مقیاس بزرگ محبوبیت پیدا کرده است.

  این داده‌ها در بستر \hyperlink{https://huggingface.co/PerSpaCor}{HuggingFace} \LTRfootnote{\url{https://huggingface.co/PerSpaCor/}}انتشار پیدا کرده‌اند. دیتاست‌های به دست آمده شامل تمام داده‌های ما هستند. به ازای هر یک از جملات، متن جمله، توکن‌های جملات، برچسب‌های اجزای کلام، کاراکتر‌های غیر فاصله و برچسب‌های فاصله قرار گرفته‌اند که این داده‌ها با چنین ساختاری، می‌توانند در پژوهش‌های متعددی استفاده شوند. شکل \ref{fig:dataset_preview} مثالی از داده‌های ما را نشان می‌دهد.
\begin{figure}[H]
      \centering
      \includegraphics[width=1\linewidth]{Figures/Screenshot from 2024-04-02 20-13-44.png}
      \caption{ نمونه‌ای از دیتاست جمع‌آوری شده}
      \label{fig:dataset_preview}
  \end{figure}




\section{پیش‌پردازشگر و برچسب‌گذار}
\hspace{30pt}
کار کردن با داده شامل ظرافت‌هایی است که نیازمند تجربه و زمان بسیار زیادی می‌باشد. با توجه به زمان زیادی که برای پیش‌پردازش و برچسب‌گذاری این پژوهش صرف کرده‌ایم، به این نتیجه رسیدیم که این دو ماژول را با تغییراتی، در دسترس عموم قرار‌ دهیم. این دو ماژول، در وب سایت

\hyperlink{https://github.com/MatinEbrahimkhani/PerSpaCor_components}{Github} \LTRfootnote{\url{https://github.com/MatinEbrahimkhani/PerSpaCor_components}}  در یک مخزن عمومی در دسترس می‌باشند. این ماژول‌ها به همراه مستندات کافی برای استفاده از آن‌ها منتشر شده‌اند. در ادامه با هر  یک از این ماژول‌ها و کارایی آن‌ها آشنا می‌شویم.

\subsection{پیش‌پردازشگر}
\hspace{30pt}
این مارول قادر است هر دو بدنه را به یک شکل پیش‌پردازش کند. ماژول ابتدا لیست توکن‌ها را دریافت می‌کند و چهار نوع داده که پیش‌تر با آن‌ها آشنا شدیم بر‌می‌گرداند. این ماژول به دلیل پیاده سازی شی‌گرا، انعطاف بالایی دارد و می‌تواند با تغییرات جزئی، انواع داده‌های متنی که به صورت ورودی دریافت می‌کند را پیش‌پردازش کند.

\subsection{برچسب‌گذار}
\hspace{30pt}
پیش‌تر در مورد برچسب گذار در این پایان‌نامه صحبت شده است . ماژول برچسب گذار ما قادر به برچسب‌گذاری هر متنی هست که می‌توان بر روی آن از عبارات با قاعده استفاده کرد. با انجام دادن تغییراتی در شروط برچسب‌گذاری, این برچسب‌گذار قادر به برچسب‌گذاری سری‌های توالی غیر متنی مانند داده‌های بازار مالی نیز هست.


\section{مدل‌ها}
\hspace{30pt}
برای سنجش مدل از معیار‌های دقت صحت درستی و امتیاز \lr{F1} استفاده کردیم. هر شش مدل ما، به نتایج قابل توجه‌ای رسیدند که بر اساس معیارهای متداول بررسی شده‌اند. دقت این مدل‌ها تشابه زیادی با یکدیگر دارند و این موضوع قابل پیش‌بینی بود چرا که تفاوت‌های ساختاری زیادی ندارند اختلاف در نتایج بیشتر تاثیر گرفته از آموزش آن‌ها بوده است. علاوه بر این موضوع نسبت معیار های مختلف هر مدل به یکدیگر مشابه یکدیگر است. دلیل این اتفاق همسان بودن آموزش‌ها و نحوه‌ی آموزش و همچنین همسان بودن تابع هزینه همه‌ی مدل ها می‌باشد. نتایج به دست آمده به شکل زیر است.

\begin{table}[H]
\centering
\caption{نتایج ارزیابی پارس‌برت}
\label{tab:bijankhan metrics}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{5}{|c|}{\textbf{bert-base-parsbert-uncased}}\\
\hline
\textbf{کلاس}                               & \multicolumn{1}{l|}{\textbf{دقت (precision)}} & \multicolumn{1}{l|}{\textbf{صحت (recall)}} & \multicolumn{1}{l|}{\textbf{درستی (accuracy)}} & \multicolumn{1}{l|}{\textbf{\lr
{F1-score}}}  \\
\hline
\textbf{صفر (همه)}                          & $1$                                           & $2$                                        & $3$                                            & $4$                                                           \\
\hline
\textbf{یک (فاصله)}                         & $5$                                           & $6$                                        & $7$                                            & $8$                                                           \\
\hline
\textbf{دو (نیم‌فاصله)}                     & $9$                                           & $10$                                       & $11$                                           & $12$                                                          \\
\hline
\textbf{میانگین کلان}                     & $13$                                           & $14$                                       & $15$                                           & $16$                                                          \\
\hline
\end{tabular}
\end{table}


\begin{table}[H]
\centering
\caption{نتایج ارزیابی برت چند‌زبانه}
\label{tab:bijankhan metrics}
\begin{tabular}{|r|c|c|c|c|}
\hline
\multicolumn{5}{|c|}{\textbf{bert-base-parsbert-uncased}}\\
\hline
\textbf{کلاس}                               & \multicolumn{1}{l|}{\textbf{دقت (precision)}} & \multicolumn{1}{l|}{\textbf{صحت (recall)}} & \multicolumn{1}{l|}{\textbf{درستی (accuracy)}} & \multicolumn{1}{l|}{\textbf{\lr
{F1-score}}}  \\
\hline
\textbf{صفر (همه)}                          & $1$                                           & $2$                                        & $3$                                            & $4$                                                           \\
\hline
\textbf{یک (فاصله)}                         & $5$                                           & $6$                                        & $7$                                            & $8$                                                           \\
\hline
\textbf{دو (نیم‌فاصله)}                     & $9$                                           & $10$                                       & $11$                                           & $12$                                                          \\
\hline
\textbf{میانگین کلان}                     & $13$                                           & $14$                                       & $15$                                           & $16$                                                          \\
\hline
\end{tabular}
\end{table}
\begin{table}[H]
 \centering
     \caption{ مقایسه میانگین کلان معیارهای مدل‌ها}
    \label{tab:model_compare}
\begin{tabular}{|lcccc|}
\hline
\multicolumn{1}{|c|}{\textbf{مدل}} & \multicolumn{1}{c|}{\textbf{دقت}} & \multicolumn{1}{c|}{\textbf{صحت}}           & \multicolumn{1}{c|}{\textbf{درستی}} & \textbf{\lr{F1-score}}  \\
\hline
bert-multilingual-uncased     & $0.97164$                                     & $0.971198$                                           & $0.971198$                                     & $0.971422$         \\
\hline
bert-multilingual-cased       & $0.97104$                                     & $0.971655$                                           & $0.971655$                                     & $0.971347$         \\
\hline
parsbert-uncased         & $0.96755$                                     & $0.970073$                                           & $0.970073$                                     & $0.968808$         \\
\hline
bert-fa-zwnj-base                  & $0.95710$                                     & \begin{tabular}[c]{@{}c@{}}$0.953585$\\\end{tabular} & $0.953585$                                     & $0.955320$         \\
\hline
roberta-fa-zwnj-base               & $0.95643$                                     & $0.954307$                                           & $0.954307$                                     & $0.955363$         \\
\hline
charbert-roberta-wiki              & $0.95297$                                     & $0.951769$                                           & $0.951769$                                     & $0.952361$         \\
\hline
\end{tabular}
\end{table}

از نتایج به دست آمده می‌توان به این نتیجه رسید، که برت‌های چندزبانه نتایج بهتری نسبت به سایر مدل‌ها دارند. دلیل این موضوع می‌تواند این باشد که پیش‌آموزش آن‌ها با اختلاف بیشتر از  سایر مدل‌ها بوده است. با این وجود مدل‌های پارس‌برت و پارس‌برت حساس به نیم‌فاصله با اختلاف کمی عملکرد ضعیف‌تر از برت‌های چندزبانه داشته‌اند. و پس از آن‌ها پارس‌روبرتا و کربرت قرار می‌گیرد.
عملکرد کربرت با توجه به عدم آموزش آن بر روی داده‌های فارسی پیش‌بینی پذیر بود. ولی عملکرد  پارس‌روبرتا با توجه به نتایج بهتر روبرتای اصلی نسبت به برت اصلی، آموزش این مدل بر روی زبان فارسی و همچنین حساس بودن آن بر روی نیم‌فاصله دور از انتظار واقع شد.

هر شش مدل این پژوهش پس از آموزش در قالب مشخصی ذخیره سازی شده‌اند. این مدل‌ها در بستر \hyperlink{https://huggingface.co/PerSpaCor}{HuggingFace} \LTRfootnote{\url{https://huggingface.co/PerSpaCor/}} به اشتراک گذاشته شده‌اند. قالب ذخیره سازی این مدل‌ها استاندارد است و می‌توان با استفاده از کتابخانه‌های مختلف یادگیری عمیق از آن‌ها استفاده کرد.

\section{وب‌سايت}
\hspace{30pt}
آخرین محصول این پژوهش وب‌سايت آن \hyperlink{https://perspacor.ir/}{perspacor.ir} \LTRfootnote{\url{https://perspacor.ir/}} است که کار تصحیح فاصله و نیم‌فاصله را برای متون فارسی انجام می‌دهد. کاربر با وارد شدن به وب‌سایت، مدل مورد نظر خود را انتخاب می‌کند و با وارد کردن متن مورد نظر در درگاه صحیح، خروجی مدل را دریافت می‌کند. کاربر می‌تواند با استفاده از همین وب‌سایت تغییرات مورد نظر بر روی خروجی مدل انجام دهد و متن نهایی خود را دریافت نماید.
هدف این وب سایت ساخت یک ابزار برای بهبود کیفیت متن‌های فارسی به طور عمومی است. شکل \ref{fig:website_preview} نمایی از این وب‌سایت را نشان می‌دهد
\begin{figure}[H]
      \centering
      \includegraphics[width=1\linewidth]{Figures/05-website_preview.png}
      \caption{  نمایی از این وب سایت \lr{perspacor.ir}}
      \label{fig:website_preview}
  \end{figure}
\chapter{جمع‌بندی و کارهای آتی}
حاصل این پژوهش با تمام نقاط قوت و ضعفش توانسته خود را از کارهای پیشین متمایز سازد و نتایج خوبی در معیارها به ما نشان دهد. برداشت ما از این موضوع این است که مسیر را به درستی رفته‌ایم  توانسته‌ایم به نتایج خوبی دست پیدا کنیم. داده‌های حاصل از این پژوهش ساخت یافته و قابل استناد هستند و به نسبت بدنه‌های اصلی بهبود قابل توجه‌ای در کارایی پیدا کرده‌اند. همچنین تصحیح‌های انجام شده بر روی بدنه‌ها موجب افزایش کیفیت آن‌ها شده است. پیش پردازشگر و برچسب‌گذار ما نیز می‌توانند طیف مشخصی از داده‌ها را پردازش و برچسب‌گذاری کنند و این در بسیاری از پژوهش‌ها می‌تواند نقش کلیدی ایفا کند. مدل‌های حاصل از این پژوهش به بالاترین معیارها در این زمینه دست پیدا کردند. این مدل‌ها اصلی‌ترین محصول این پژوهش هستند که با نتایج خود توانسته‌اند اهمیت خود را به ما نشان دهند.
و در نهایت وب سایت \lr{perspacor.ir} قابلیت‌های این پژوهش را ر معرض انظار عمومی قرار می‌دهد و نشان می‌دهد که این مدل‌ها توانایی پردازش متن‌های دنیای واقعی را نیز دارند.


دامنه این پژوهش را به واسطه کار بر روی صرف فاصله و نیم‌فاصله، می‌توان کوچک شمرد. با این وجود نتایج نشان می‌دهد که روشی صحیح برای پردازش سری‌های متوالی در پیش گرفته‌ایم و این موضوع می‌تواند در پژوهش‌های آتی چه در زمینه تصحیح متن و چه در زمینه‌های پژوهش دیگر مورد توجه قرار بگیرد.


منابعی که در این پژوهش استفاده شده‌اند، محدود بوده‌اند. افزودن به این منابع، از جمله افزایش داده ورودی مدل‌ها، استفاده از سخت‌افزارهای بهتر و بزرگتر ممکن است بتواند نتایجی بهتر از نتایج ما را رقم بزند. اگر به این پژوهش به مانند یک آزمایش نگاه کنیم، با در نظر گرفتن تمام منابع استفاده شده. می‌توان گفت که راه برای بهبود آن به وسیله افزایش منابع هموار است.


کارهای متعددی می‌توان بر روی این پژوهش انجام داد؛ از جمله این کارها تهیه و پیاده‌سازی یک معیار مشخص برای بهبود عملکرد مدل بر روی یک سری معیارهای مشخص است. به طور مشخص تغییر دادن تابع هزینه مدل یادگیری عمیق به نحوی که بتواند یک معیاری مشخص را بیشینه کند. می‌توان این مفهوم را بر روی سایر کاراکترها همچون نقطه و ویرگول و به صورت کلی اصلاح ایرادات نحوی در متون استفاده کرد. با تغییر در ساختار شبکه عصبی مدل، افزودن لایه‌های نگاشتگر قبل از مدل، می‌توان به توکنیزه‌سازی حروف کمک کرد و نتایج نهایی را بهبود بخشید. تغییر شیوه برچسب‌گذاری می‌تواند ایده جالبی برای تغییر کارایی مدل و استفاده کردن از آن به عنوان یک مدل چند کاره باشد. و در آخر یکی از کارهایی که شاید بتواند کارایی مدل را افزایش دهد، دخالت دادن اجزای کلام در آموزش مدل‌ها است.


در نهایت امیدواریم که این پژوهش الهام بخش پژوهشگرانی باشد که می‌توانند به کارها و نتایج جدید و بهتر از ما برسند. در تمام مراحل انجام این پژوهش در دسترس بودن و قابل استفاده بودن برای کارهای دیگر در نظر گرفته شده است و این موضوع به عنوان یک هدف مهم برای ما تعریف شده است که رسیدن به آن شاید دشوارترین هدف این پژوهش بوده است. با این حال، آرزو داریم که این پژوهش اول راه بسیاری از پژوهش‌های محققان باشد.
